{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "#from keras.utils import np_utilsy\n",
    "from keras import backend as K\n",
    "import os\n",
    "import gc\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If using GPU.\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['reduced_data', 'waveforms', 'yeofrho']>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read database.\n",
    "f = h5py.File('GWdatabase.h5','r')   \n",
    "f.keys()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list that contains all the failure cases.\n",
    "fail_num = []\n",
    "index = 0\n",
    "for item in f['reduced_data']['tbounce(s)']:\n",
    "    if(item == -1):\n",
    "        fail_num.append(index)\n",
    "    index += 1\n",
    "fail_case = []\n",
    "for index in fail_num:\n",
    "    fail_case.append([f['reduced_data']['A(km)'][index],f['reduced_data']['omega_0(rad|s)'][index],f['reduced_data']['EOS'][index]])\n",
    "fail_list= []\n",
    "for item in fail_case:\n",
    "    tmp = str(item[2]).split(\"b'\")[1].split(\"'\")[0]\n",
    "    tmp = \"A\" + str(int(item[0])) + \"w\" + str(item[1]) + \"0_\" + tmp\n",
    "    fail_list.append(tmp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1482"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_num = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        #if(float(item.split('_')[0].split('w')[0].split('A')[1]) == 300):\n",
    "        if(str(item.split('_')[1]) != 'LS180' and str(item.split('_')[1]) != 'LS220' and \n",
    "        str(item.split('_')[1]) != 'LS375'):\n",
    "            A_num.append(index)\n",
    "    index+=1\n",
    "len(A_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the label of w.\n",
    "y_train = []\n",
    "y_test = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        if(index in A_num):\n",
    "            y_train.append(float(item.split('_')[0].split('w')[1]))\n",
    "        else:\n",
    "            y_test.append(float(item.split('_')[0].split('w')[1]))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image data.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "X_train = []\n",
    "X_test = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        if(index in A_num):\n",
    "            #for j in range(5):\n",
    "                #title = 'Final_EOS/'+ str(index) + \"_\" + str(j) + '.jpeg' \n",
    "            title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "            image = Image.open(title).convert('L')\n",
    "            X_train.append(np.array(image))\n",
    "        else:\n",
    "            title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "            image = Image.open(title).convert('L')\n",
    "            X_test.append(np.array(image))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_train = X_train.reshape(X_train.shape[0], 256, 256, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using one hot to encode the label.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(256, 256, 1), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='softmax'))\n",
    "#model.add(Dense(1, activation='relu'))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n",
    "#optimizer = keras.optimizers.Adam(learning_rate=0.000003)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "#model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "93/93 [==============================] - 10s 74ms/step - loss: 7.1902 - acc: 0.0366 - val_loss: 3.4280 - val_acc: 0.0851\n",
      "Epoch 2/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 3.5546 - acc: 0.0336 - val_loss: 3.3465 - val_acc: 0.0532\n",
      "Epoch 3/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 3.4635 - acc: 0.0506 - val_loss: 3.3385 - val_acc: 0.0532\n",
      "Epoch 4/120\n",
      "93/93 [==============================] - 6s 59ms/step - loss: 3.3849 - acc: 0.0582 - val_loss: 3.3104 - val_acc: 0.0532\n",
      "Epoch 5/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 3.3450 - acc: 0.0541 - val_loss: 3.2987 - val_acc: 0.0816\n",
      "Epoch 6/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 3.3499 - acc: 0.0464 - val_loss: 3.2666 - val_acc: 0.0532\n",
      "Epoch 7/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 3.2952 - acc: 0.0609 - val_loss: 3.1652 - val_acc: 0.0674\n",
      "Epoch 8/120\n",
      "93/93 [==============================] - 6s 59ms/step - loss: 3.1880 - acc: 0.1103 - val_loss: 2.9940 - val_acc: 0.1418\n",
      "Epoch 9/120\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 3.0120 - acc: 0.0897 - val_loss: 2.8390 - val_acc: 0.1277\n",
      "Epoch 10/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 2.8405 - acc: 0.1441 - val_loss: 2.6668 - val_acc: 0.1809\n",
      "Epoch 11/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 2.7121 - acc: 0.1568 - val_loss: 2.5226 - val_acc: 0.2199\n",
      "Epoch 12/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 2.6227 - acc: 0.1570 - val_loss: 2.4086 - val_acc: 0.1738\n",
      "Epoch 13/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 2.4923 - acc: 0.1753 - val_loss: 2.2699 - val_acc: 0.2270\n",
      "Epoch 14/120\n",
      "93/93 [==============================] - 6s 59ms/step - loss: 2.4052 - acc: 0.1945 - val_loss: 2.1681 - val_acc: 0.2979\n",
      "Epoch 15/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 2.2995 - acc: 0.2254 - val_loss: 2.1280 - val_acc: 0.2872\n",
      "Epoch 16/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 2.2390 - acc: 0.2401 - val_loss: 2.0589 - val_acc: 0.2908\n",
      "Epoch 17/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 2.1424 - acc: 0.2459 - val_loss: 1.9943 - val_acc: 0.2908\n",
      "Epoch 18/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 2.1154 - acc: 0.2401 - val_loss: 2.0194 - val_acc: 0.2730\n",
      "Epoch 19/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 2.0787 - acc: 0.2390 - val_loss: 2.0006 - val_acc: 0.2979\n",
      "Epoch 20/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.9243 - acc: 0.3130 - val_loss: 1.8269 - val_acc: 0.3333\n",
      "Epoch 21/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.8881 - acc: 0.3062 - val_loss: 1.9817 - val_acc: 0.3298\n",
      "Epoch 22/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.8475 - acc: 0.3255 - val_loss: 1.8300 - val_acc: 0.3333\n",
      "Epoch 23/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.7739 - acc: 0.3421 - val_loss: 1.7427 - val_acc: 0.3511\n",
      "Epoch 24/120\n",
      "93/93 [==============================] - 6s 59ms/step - loss: 1.7806 - acc: 0.3274 - val_loss: 1.7824 - val_acc: 0.3050\n",
      "Epoch 25/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 1.7264 - acc: 0.3620 - val_loss: 1.7945 - val_acc: 0.3227\n",
      "Epoch 26/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.6753 - acc: 0.3790 - val_loss: 1.7260 - val_acc: 0.3475\n",
      "Epoch 27/120\n",
      "93/93 [==============================] - 6s 61ms/step - loss: 1.6332 - acc: 0.3856 - val_loss: 1.6517 - val_acc: 0.3582\n",
      "Epoch 28/120\n",
      "93/93 [==============================] - 6s 59ms/step - loss: 1.5567 - acc: 0.4221 - val_loss: 1.7029 - val_acc: 0.3582\n",
      "Epoch 29/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.5407 - acc: 0.4007 - val_loss: 1.7032 - val_acc: 0.3475\n",
      "Epoch 30/120\n",
      "93/93 [==============================] - 6s 61ms/step - loss: 1.5092 - acc: 0.4460 - val_loss: 1.6846 - val_acc: 0.3582\n",
      "Epoch 31/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.4636 - acc: 0.4301 - val_loss: 1.6701 - val_acc: 0.3688\n",
      "Epoch 32/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.4084 - acc: 0.4406 - val_loss: 1.6766 - val_acc: 0.3582\n",
      "Epoch 33/120\n",
      "93/93 [==============================] - 6s 61ms/step - loss: 1.3841 - acc: 0.4695 - val_loss: 1.6053 - val_acc: 0.3723\n",
      "Epoch 34/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 1.3561 - acc: 0.4855 - val_loss: 1.5642 - val_acc: 0.3865\n",
      "Epoch 35/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.3875 - acc: 0.4451 - val_loss: 1.5739 - val_acc: 0.3865\n",
      "Epoch 36/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.2918 - acc: 0.4763 - val_loss: 1.5488 - val_acc: 0.4043\n",
      "Epoch 37/120\n",
      "93/93 [==============================] - 6s 59ms/step - loss: 1.2612 - acc: 0.5073 - val_loss: 1.5846 - val_acc: 0.3333\n",
      "Epoch 38/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 1.2009 - acc: 0.5087 - val_loss: 1.5636 - val_acc: 0.3901\n",
      "Epoch 39/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 1.2077 - acc: 0.5273 - val_loss: 1.5389 - val_acc: 0.4255\n",
      "Epoch 40/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 1.1220 - acc: 0.5593 - val_loss: 1.5460 - val_acc: 0.4255\n",
      "Epoch 41/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.1624 - acc: 0.5568 - val_loss: 1.4953 - val_acc: 0.3972\n",
      "Epoch 42/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 1.0511 - acc: 0.5827 - val_loss: 1.4490 - val_acc: 0.4362\n",
      "Epoch 43/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 1.0743 - acc: 0.5845 - val_loss: 1.5130 - val_acc: 0.4255\n",
      "Epoch 44/120\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.0335 - acc: 0.5902 - val_loss: 1.4284 - val_acc: 0.4645\n",
      "Epoch 45/120\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0221 - acc: 0.6043 - val_loss: 1.3845 - val_acc: 0.4965\n",
      "Epoch 46/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.9769 - acc: 0.6167 - val_loss: 1.4433 - val_acc: 0.4433\n",
      "Epoch 47/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.9548 - acc: 0.6079 - val_loss: 1.5001 - val_acc: 0.4326\n",
      "Epoch 48/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.9002 - acc: 0.6444 - val_loss: 1.4137 - val_acc: 0.4504\n",
      "Epoch 49/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.8813 - acc: 0.6515 - val_loss: 1.5008 - val_acc: 0.4220\n",
      "Epoch 50/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.9277 - acc: 0.6356 - val_loss: 1.3800 - val_acc: 0.4823\n",
      "Epoch 51/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.8588 - acc: 0.6692 - val_loss: 1.4225 - val_acc: 0.4645\n",
      "Epoch 52/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.8640 - acc: 0.6772 - val_loss: 1.3990 - val_acc: 0.4645\n",
      "Epoch 53/120\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8176 - acc: 0.6875 - val_loss: 1.4002 - val_acc: 0.4787\n",
      "Epoch 54/120\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7723 - acc: 0.7139 - val_loss: 1.3155 - val_acc: 0.4929\n",
      "Epoch 55/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.8077 - acc: 0.6773 - val_loss: 1.3319 - val_acc: 0.4823\n",
      "Epoch 56/120\n",
      "93/93 [==============================] - 6s 61ms/step - loss: 0.7126 - acc: 0.7353 - val_loss: 1.3627 - val_acc: 0.5035\n",
      "Epoch 57/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.7232 - acc: 0.7384 - val_loss: 1.3532 - val_acc: 0.4787\n",
      "Epoch 58/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.6905 - acc: 0.7357 - val_loss: 1.3344 - val_acc: 0.4681\n",
      "Epoch 59/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.6932 - acc: 0.7413 - val_loss: 1.3305 - val_acc: 0.4929\n",
      "Epoch 60/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.6655 - acc: 0.7297 - val_loss: 1.3094 - val_acc: 0.4858\n",
      "Epoch 61/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.6071 - acc: 0.7870 - val_loss: 1.3226 - val_acc: 0.4539\n",
      "Epoch 62/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 5s 59ms/step - loss: 0.6465 - acc: 0.7568 - val_loss: 1.3411 - val_acc: 0.5071\n",
      "Epoch 63/120\n",
      "93/93 [==============================] - 6s 59ms/step - loss: 0.6427 - acc: 0.7476 - val_loss: 1.3905 - val_acc: 0.4858\n",
      "Epoch 64/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.5914 - acc: 0.7847 - val_loss: 1.2668 - val_acc: 0.5319\n",
      "Epoch 65/120\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.5577 - acc: 0.8041 - val_loss: 1.3021 - val_acc: 0.4965\n",
      "Epoch 66/120\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5419 - acc: 0.8074 - val_loss: 1.2311 - val_acc: 0.5177\n",
      "Epoch 67/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.4876 - acc: 0.8410 - val_loss: 1.2885 - val_acc: 0.5248\n",
      "Epoch 68/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.5277 - acc: 0.7966 - val_loss: 1.3449 - val_acc: 0.5142\n",
      "Epoch 69/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.4933 - acc: 0.8216 - val_loss: 1.3145 - val_acc: 0.5248\n",
      "Epoch 70/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.4633 - acc: 0.8465 - val_loss: 1.3479 - val_acc: 0.5106\n",
      "Epoch 71/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.4835 - acc: 0.8337 - val_loss: 1.2642 - val_acc: 0.5496\n",
      "Epoch 72/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.4239 - acc: 0.8628 - val_loss: 1.2988 - val_acc: 0.5035\n",
      "Epoch 73/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.4580 - acc: 0.8280 - val_loss: 1.2959 - val_acc: 0.5355\n",
      "Epoch 74/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.4151 - acc: 0.8606 - val_loss: 1.2775 - val_acc: 0.5213\n",
      "Epoch 75/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.4154 - acc: 0.8534 - val_loss: 1.2705 - val_acc: 0.5426\n",
      "Epoch 76/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.3668 - acc: 0.8888 - val_loss: 1.3057 - val_acc: 0.5426\n",
      "Epoch 77/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.3828 - acc: 0.8644 - val_loss: 1.2742 - val_acc: 0.5674\n",
      "Epoch 78/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.4010 - acc: 0.8560 - val_loss: 1.2720 - val_acc: 0.5567\n",
      "Epoch 79/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.3401 - acc: 0.8973 - val_loss: 1.3516 - val_acc: 0.5496\n",
      "Epoch 80/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.3828 - acc: 0.8686 - val_loss: 1.3232 - val_acc: 0.5496\n",
      "Epoch 81/120\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.3379 - acc: 0.8820 - val_loss: 1.4066 - val_acc: 0.4965\n",
      "Epoch 82/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.3249 - acc: 0.8989 - val_loss: 1.2745 - val_acc: 0.5461\n",
      "Epoch 83/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.3024 - acc: 0.8930 - val_loss: 1.2162 - val_acc: 0.5887\n",
      "Epoch 84/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.3181 - acc: 0.8853 - val_loss: 1.3452 - val_acc: 0.5000\n",
      "Epoch 85/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.2893 - acc: 0.9001 - val_loss: 1.2406 - val_acc: 0.5922\n",
      "Epoch 86/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.2664 - acc: 0.9159 - val_loss: 1.3680 - val_acc: 0.5284\n",
      "Epoch 87/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.2853 - acc: 0.9149 - val_loss: 1.3640 - val_acc: 0.5496\n",
      "Epoch 88/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.2595 - acc: 0.9124 - val_loss: 1.3807 - val_acc: 0.5248\n",
      "Epoch 89/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.2605 - acc: 0.9263 - val_loss: 1.3557 - val_acc: 0.5567\n",
      "Epoch 90/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.2617 - acc: 0.9148 - val_loss: 1.3007 - val_acc: 0.5638\n",
      "Epoch 91/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.2444 - acc: 0.9260 - val_loss: 1.4239 - val_acc: 0.5035\n",
      "Epoch 92/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.2366 - acc: 0.9192 - val_loss: 1.3075 - val_acc: 0.5957\n",
      "Epoch 93/120\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.2126 - acc: 0.9296 - val_loss: 1.2941 - val_acc: 0.5887\n",
      "Epoch 94/120\n",
      "93/93 [==============================] - 6s 59ms/step - loss: 0.2271 - acc: 0.9286 - val_loss: 1.3380 - val_acc: 0.5638\n",
      "Epoch 95/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.2241 - acc: 0.9283 - val_loss: 1.4261 - val_acc: 0.5603\n",
      "Epoch 96/120\n",
      "93/93 [==============================] - 6s 61ms/step - loss: 0.2099 - acc: 0.9300 - val_loss: 1.3673 - val_acc: 0.5496\n",
      "Epoch 97/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.2084 - acc: 0.9359 - val_loss: 1.3726 - val_acc: 0.5496\n",
      "Epoch 98/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1999 - acc: 0.9347 - val_loss: 1.3943 - val_acc: 0.5319\n",
      "Epoch 99/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1708 - acc: 0.9522 - val_loss: 1.5641 - val_acc: 0.5071\n",
      "Epoch 100/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1770 - acc: 0.9492 - val_loss: 1.4448 - val_acc: 0.5532\n",
      "Epoch 101/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.2032 - acc: 0.9415 - val_loss: 1.4094 - val_acc: 0.5638\n",
      "Epoch 102/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1698 - acc: 0.9430 - val_loss: 1.4093 - val_acc: 0.5674\n",
      "Epoch 103/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1662 - acc: 0.9468 - val_loss: 1.3624 - val_acc: 0.5816\n",
      "Epoch 104/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1613 - acc: 0.9521 - val_loss: 1.4102 - val_acc: 0.5532\n",
      "Epoch 105/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1664 - acc: 0.9514 - val_loss: 1.4319 - val_acc: 0.5426\n",
      "Epoch 106/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1551 - acc: 0.9558 - val_loss: 1.4551 - val_acc: 0.6135\n",
      "Epoch 107/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1314 - acc: 0.9660 - val_loss: 1.3663 - val_acc: 0.5390\n",
      "Epoch 108/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1543 - acc: 0.9534 - val_loss: 1.4241 - val_acc: 0.5177\n",
      "Epoch 109/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1300 - acc: 0.9670 - val_loss: 1.4498 - val_acc: 0.5035\n",
      "Epoch 110/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1355 - acc: 0.9655 - val_loss: 1.5165 - val_acc: 0.5035\n",
      "Epoch 111/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1540 - acc: 0.9527 - val_loss: 1.4141 - val_acc: 0.6135\n",
      "Epoch 112/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1393 - acc: 0.9609 - val_loss: 1.4747 - val_acc: 0.5461\n",
      "Epoch 113/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1296 - acc: 0.9643 - val_loss: 1.4529 - val_acc: 0.5709\n",
      "Epoch 114/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1230 - acc: 0.9708 - val_loss: 1.3954 - val_acc: 0.5532\n",
      "Epoch 115/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1001 - acc: 0.9739 - val_loss: 1.4178 - val_acc: 0.6312\n",
      "Epoch 116/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1138 - acc: 0.9718 - val_loss: 1.4012 - val_acc: 0.5851\n",
      "Epoch 117/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1342 - acc: 0.9508 - val_loss: 1.4391 - val_acc: 0.5638\n",
      "Epoch 118/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1074 - acc: 0.9708 - val_loss: 1.4747 - val_acc: 0.5567\n",
      "Epoch 119/120\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1117 - acc: 0.9701 - val_loss: 1.5001 - val_acc: 0.5426\n",
      "Epoch 120/120\n",
      "93/93 [==============================] - 6s 61ms/step - loss: 0.0937 - acc: 0.9732 - val_loss: 1.5381 - val_acc: 0.5674\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=120, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "95/95 [==============================] - 7s 66ms/step - loss: 6.6286 - acc: 0.0299 - val_loss: 3.3804 - val_acc: 0.0781\n",
      "Epoch 2/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 3.5126 - acc: 0.0462 - val_loss: 3.3492 - val_acc: 0.0586\n",
      "Epoch 3/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 3.4319 - acc: 0.0464 - val_loss: 3.3114 - val_acc: 0.0586\n",
      "Epoch 4/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 3.3594 - acc: 0.0683 - val_loss: 3.3000 - val_acc: 0.0469\n",
      "Epoch 5/120\n",
      "95/95 [==============================] - 6s 60ms/step - loss: 3.3732 - acc: 0.0341 - val_loss: 3.2759 - val_acc: 0.1250\n",
      "Epoch 6/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 3.3522 - acc: 0.0661 - val_loss: 3.2573 - val_acc: 0.0820\n",
      "Epoch 7/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 3.2925 - acc: 0.0602 - val_loss: 3.1764 - val_acc: 0.0586\n",
      "Epoch 8/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 3.2428 - acc: 0.0918 - val_loss: 3.0943 - val_acc: 0.1211\n",
      "Epoch 9/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 3.1287 - acc: 0.1120 - val_loss: 2.8954 - val_acc: 0.1367\n",
      "Epoch 10/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 2.9950 - acc: 0.1215 - val_loss: 2.7666 - val_acc: 0.1172\n",
      "Epoch 11/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 2.8089 - acc: 0.1314 - val_loss: 2.5579 - val_acc: 0.1836\n",
      "Epoch 12/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 2.6522 - acc: 0.1707 - val_loss: 2.4134 - val_acc: 0.2305\n",
      "Epoch 13/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 2.5258 - acc: 0.1814 - val_loss: 2.2715 - val_acc: 0.1914\n",
      "Epoch 14/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 2.4524 - acc: 0.2021 - val_loss: 2.1656 - val_acc: 0.3047\n",
      "Epoch 15/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 2.3295 - acc: 0.1986 - val_loss: 2.1213 - val_acc: 0.2383\n",
      "Epoch 16/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 2.2024 - acc: 0.2485 - val_loss: 2.0296 - val_acc: 0.2734\n",
      "Epoch 17/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 2.1366 - acc: 0.2496 - val_loss: 2.0030 - val_acc: 0.2930\n",
      "Epoch 18/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 2.0815 - acc: 0.2351 - val_loss: 1.8870 - val_acc: 0.3164\n",
      "Epoch 19/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.9709 - acc: 0.3058 - val_loss: 1.8728 - val_acc: 0.3008\n",
      "Epoch 20/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.9480 - acc: 0.2681 - val_loss: 1.8113 - val_acc: 0.3242\n",
      "Epoch 21/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.8929 - acc: 0.3168 - val_loss: 1.7646 - val_acc: 0.3203\n",
      "Epoch 22/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.8793 - acc: 0.3200 - val_loss: 1.7314 - val_acc: 0.3008\n",
      "Epoch 23/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.7879 - acc: 0.3382 - val_loss: 1.6495 - val_acc: 0.3398\n",
      "Epoch 24/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.7057 - acc: 0.3532 - val_loss: 1.6136 - val_acc: 0.3398\n",
      "Epoch 25/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.6381 - acc: 0.3856 - val_loss: 1.5443 - val_acc: 0.3789\n",
      "Epoch 26/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.6105 - acc: 0.4024 - val_loss: 1.5704 - val_acc: 0.3711\n",
      "Epoch 27/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.5325 - acc: 0.4272 - val_loss: 1.4990 - val_acc: 0.3906\n",
      "Epoch 28/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.5697 - acc: 0.4206 - val_loss: 1.4680 - val_acc: 0.4141\n",
      "Epoch 29/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.4657 - acc: 0.4234 - val_loss: 1.4873 - val_acc: 0.3789\n",
      "Epoch 30/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.4440 - acc: 0.4646 - val_loss: 1.4347 - val_acc: 0.3867\n",
      "Epoch 31/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.3863 - acc: 0.4590 - val_loss: 1.3653 - val_acc: 0.4023\n",
      "Epoch 32/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.3402 - acc: 0.4873 - val_loss: 1.3129 - val_acc: 0.4180\n",
      "Epoch 33/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.2609 - acc: 0.5400 - val_loss: 1.3246 - val_acc: 0.4336\n",
      "Epoch 34/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 1.2600 - acc: 0.4989 - val_loss: 1.2310 - val_acc: 0.4961\n",
      "Epoch 35/120\n",
      "95/95 [==============================] - 6s 60ms/step - loss: 1.2213 - acc: 0.5137 - val_loss: 1.2387 - val_acc: 0.5156\n",
      "Epoch 36/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 1.1982 - acc: 0.5450 - val_loss: 1.2171 - val_acc: 0.4766\n",
      "Epoch 37/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 1.1450 - acc: 0.5588 - val_loss: 1.1931 - val_acc: 0.4883\n",
      "Epoch 38/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 1.1258 - acc: 0.5439 - val_loss: 1.1498 - val_acc: 0.5234\n",
      "Epoch 39/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 1.1187 - acc: 0.5387 - val_loss: 1.1448 - val_acc: 0.5430\n",
      "Epoch 40/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 1.0956 - acc: 0.5734 - val_loss: 1.1087 - val_acc: 0.5586\n",
      "Epoch 41/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 1.0263 - acc: 0.6063 - val_loss: 1.1107 - val_acc: 0.5352\n",
      "Epoch 42/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 1.0296 - acc: 0.5980 - val_loss: 1.0910 - val_acc: 0.5508\n",
      "Epoch 43/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.9752 - acc: 0.6259 - val_loss: 1.0764 - val_acc: 0.5625\n",
      "Epoch 44/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.9359 - acc: 0.6415 - val_loss: 1.0408 - val_acc: 0.5312\n",
      "Epoch 45/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.9052 - acc: 0.6675 - val_loss: 1.0021 - val_acc: 0.5977\n",
      "Epoch 46/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.8652 - acc: 0.6668 - val_loss: 1.0096 - val_acc: 0.5781\n",
      "Epoch 47/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.8771 - acc: 0.6625 - val_loss: 0.9956 - val_acc: 0.5820\n",
      "Epoch 48/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.8260 - acc: 0.7000 - val_loss: 1.0133 - val_acc: 0.5859\n",
      "Epoch 49/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.8057 - acc: 0.6773 - val_loss: 0.9518 - val_acc: 0.5938\n",
      "Epoch 50/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.7431 - acc: 0.7463 - val_loss: 0.9252 - val_acc: 0.5938\n",
      "Epoch 51/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.7331 - acc: 0.7252 - val_loss: 0.8920 - val_acc: 0.5977\n",
      "Epoch 52/120\n",
      "95/95 [==============================] - 6s 60ms/step - loss: 0.7477 - acc: 0.7142 - val_loss: 0.8848 - val_acc: 0.6172\n",
      "Epoch 53/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.6958 - acc: 0.7364 - val_loss: 0.8754 - val_acc: 0.6133\n",
      "Epoch 54/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.6898 - acc: 0.7555 - val_loss: 0.9180 - val_acc: 0.6094\n",
      "Epoch 55/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.6748 - acc: 0.7478 - val_loss: 0.8169 - val_acc: 0.6875\n",
      "Epoch 56/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.6483 - acc: 0.7607 - val_loss: 0.8242 - val_acc: 0.6328\n",
      "Epoch 57/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.6276 - acc: 0.7619 - val_loss: 0.8261 - val_acc: 0.6406\n",
      "Epoch 58/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.5540 - acc: 0.8172 - val_loss: 0.8098 - val_acc: 0.6719\n",
      "Epoch 59/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.5776 - acc: 0.7831 - val_loss: 0.7317 - val_acc: 0.6758\n",
      "Epoch 60/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.5528 - acc: 0.8094 - val_loss: 0.7779 - val_acc: 0.6680\n",
      "Epoch 61/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.5445 - acc: 0.8046 - val_loss: 0.7598 - val_acc: 0.7188\n",
      "Epoch 62/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 5s 58ms/step - loss: 0.5176 - acc: 0.8153 - val_loss: 0.7690 - val_acc: 0.6797\n",
      "Epoch 63/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.5277 - acc: 0.8198 - val_loss: 0.7551 - val_acc: 0.6953\n",
      "Epoch 64/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.4791 - acc: 0.8340 - val_loss: 0.7108 - val_acc: 0.7227\n",
      "Epoch 65/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.4771 - acc: 0.8378 - val_loss: 0.6952 - val_acc: 0.7070\n",
      "Epoch 66/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.4471 - acc: 0.8536 - val_loss: 0.7714 - val_acc: 0.6484\n",
      "Epoch 67/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.4429 - acc: 0.8458 - val_loss: 0.7096 - val_acc: 0.7227\n",
      "Epoch 68/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.3978 - acc: 0.8718 - val_loss: 0.7473 - val_acc: 0.6758\n",
      "Epoch 69/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.4338 - acc: 0.8329 - val_loss: 0.6893 - val_acc: 0.7070\n",
      "Epoch 70/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.3639 - acc: 0.8936 - val_loss: 0.7097 - val_acc: 0.6836\n",
      "Epoch 71/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.3782 - acc: 0.8785 - val_loss: 0.6745 - val_acc: 0.7344\n",
      "Epoch 72/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.3778 - acc: 0.8670 - val_loss: 0.6541 - val_acc: 0.7461\n",
      "Epoch 73/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.3523 - acc: 0.8959 - val_loss: 0.6660 - val_acc: 0.7305\n",
      "Epoch 74/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.3697 - acc: 0.8760 - val_loss: 0.7373 - val_acc: 0.6719\n",
      "Epoch 75/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.3671 - acc: 0.8631 - val_loss: 0.6862 - val_acc: 0.7227\n",
      "Epoch 76/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.3168 - acc: 0.8946 - val_loss: 0.6752 - val_acc: 0.7383\n",
      "Epoch 77/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.3165 - acc: 0.9006 - val_loss: 0.6348 - val_acc: 0.7148\n",
      "Epoch 78/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2929 - acc: 0.9060 - val_loss: 0.6449 - val_acc: 0.7266\n",
      "Epoch 79/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2942 - acc: 0.9064 - val_loss: 0.6496 - val_acc: 0.7305\n",
      "Epoch 80/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2899 - acc: 0.9091 - val_loss: 0.6122 - val_acc: 0.7109\n",
      "Epoch 81/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2733 - acc: 0.9036 - val_loss: 0.6408 - val_acc: 0.7500\n",
      "Epoch 82/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2667 - acc: 0.9086 - val_loss: 0.6515 - val_acc: 0.6953\n",
      "Epoch 83/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2582 - acc: 0.9187 - val_loss: 0.6731 - val_acc: 0.7188\n",
      "Epoch 84/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2289 - acc: 0.9294 - val_loss: 0.6335 - val_acc: 0.7344\n",
      "Epoch 85/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2425 - acc: 0.9247 - val_loss: 0.6889 - val_acc: 0.7070\n",
      "Epoch 86/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2407 - acc: 0.9199 - val_loss: 0.6644 - val_acc: 0.7031\n",
      "Epoch 87/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2394 - acc: 0.9223 - val_loss: 0.6343 - val_acc: 0.7344\n",
      "Epoch 88/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2072 - acc: 0.9441 - val_loss: 0.6824 - val_acc: 0.6992\n",
      "Epoch 89/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2046 - acc: 0.9392 - val_loss: 0.6349 - val_acc: 0.7461\n",
      "Epoch 90/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.2219 - acc: 0.9292 - val_loss: 0.7085 - val_acc: 0.7070\n",
      "Epoch 91/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2000 - acc: 0.9378 - val_loss: 0.6215 - val_acc: 0.7656\n",
      "Epoch 92/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.2233 - acc: 0.9265 - val_loss: 0.5564 - val_acc: 0.7734\n",
      "Epoch 93/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.2013 - acc: 0.9344 - val_loss: 0.6828 - val_acc: 0.7188\n",
      "Epoch 94/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.1840 - acc: 0.9431 - val_loss: 0.6212 - val_acc: 0.7422\n",
      "Epoch 95/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.1579 - acc: 0.9580 - val_loss: 0.6099 - val_acc: 0.7188\n",
      "Epoch 96/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.1643 - acc: 0.9474 - val_loss: 0.5792 - val_acc: 0.7773\n",
      "Epoch 97/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.1522 - acc: 0.9582 - val_loss: 0.6086 - val_acc: 0.7383\n",
      "Epoch 98/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.1760 - acc: 0.9401 - val_loss: 0.5862 - val_acc: 0.7578\n",
      "Epoch 99/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.1825 - acc: 0.9456 - val_loss: 0.5768 - val_acc: 0.7773\n",
      "Epoch 100/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.1720 - acc: 0.9509 - val_loss: 0.5611 - val_acc: 0.7578\n",
      "Epoch 101/120\n",
      "95/95 [==============================] - 5s 58ms/step - loss: 0.1441 - acc: 0.9558 - val_loss: 0.5976 - val_acc: 0.7344\n",
      "Epoch 102/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.1276 - acc: 0.9716 - val_loss: 0.5185 - val_acc: 0.7812\n",
      "Epoch 103/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.1402 - acc: 0.9591 - val_loss: 0.6248 - val_acc: 0.7734\n",
      "Epoch 104/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.1413 - acc: 0.9677 - val_loss: 0.6895 - val_acc: 0.7383\n",
      "Epoch 105/120\n",
      "95/95 [==============================] - 6s 58ms/step - loss: 0.1268 - acc: 0.9670 - val_loss: 0.5766 - val_acc: 0.7578\n",
      "Epoch 106/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.1185 - acc: 0.9697 - val_loss: 0.5824 - val_acc: 0.7617\n",
      "Epoch 107/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.1402 - acc: 0.9521 - val_loss: 0.6773 - val_acc: 0.7539\n",
      "Epoch 108/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.1184 - acc: 0.9649 - val_loss: 0.6691 - val_acc: 0.7148\n",
      "Epoch 109/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.1158 - acc: 0.9616 - val_loss: 0.6897 - val_acc: 0.7305\n",
      "Epoch 110/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.1189 - acc: 0.9675 - val_loss: 0.6125 - val_acc: 0.7383\n",
      "Epoch 111/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.1325 - acc: 0.9586 - val_loss: 0.6403 - val_acc: 0.7227\n",
      "Epoch 112/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.1210 - acc: 0.9703 - val_loss: 0.6531 - val_acc: 0.7305\n",
      "Epoch 113/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.0926 - acc: 0.9740 - val_loss: 0.6583 - val_acc: 0.7305\n",
      "Epoch 114/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.1011 - acc: 0.9726 - val_loss: 0.6762 - val_acc: 0.7578\n",
      "Epoch 115/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.0886 - acc: 0.9765 - val_loss: 0.6025 - val_acc: 0.7461\n",
      "Epoch 116/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.1030 - acc: 0.9673 - val_loss: 0.6068 - val_acc: 0.7500\n",
      "Epoch 117/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.0829 - acc: 0.9850 - val_loss: 0.6198 - val_acc: 0.7734\n",
      "Epoch 118/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.1052 - acc: 0.9757 - val_loss: 0.6562 - val_acc: 0.7305\n",
      "Epoch 119/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.0911 - acc: 0.9785 - val_loss: 0.5846 - val_acc: 0.7891\n",
      "Epoch 120/120\n",
      "95/95 [==============================] - 6s 59ms/step - loss: 0.0926 - acc: 0.9744 - val_loss: 0.6627 - val_acc: 0.7383\n"
     ]
    }
   ],
   "source": [
    "A_num = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        if(str(item.split('_')[1]) != 'GShenFSU1.7' and str(item.split('_')[1]) != 'GShenFSU2.1' and \n",
    "        str(item.split('_')[1]) != 'GShenNL3'):\n",
    "            A_num.append(index)\n",
    "    index+=1\n",
    "#get the label of w.\n",
    "y_train = []\n",
    "y_test = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        if(index in A_num):\n",
    "            y_train.append(float(item.split('_')[0].split('w')[1]))\n",
    "        else:\n",
    "            y_test.append(float(item.split('_')[0].split('w')[1]))\n",
    "    index += 1\n",
    "#read image data.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "X_train = []\n",
    "X_test = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        if(index in A_num):\n",
    "            #for j in range(5):\n",
    "                #title = 'Final_EOS/'+ str(index) + \"_\" + str(j) + '.jpeg' \n",
    "            title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "            image = Image.open(title).convert('L')\n",
    "            X_train.append(np.array(image))\n",
    "        else:\n",
    "            title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "            image = Image.open(title).convert('L')\n",
    "            X_test.append(np.array(image))\n",
    "    index += 1\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_train = X_train.reshape(X_train.shape[0], 256, 256, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 256, 256, 1)\n",
    "#using one hot to encode the label.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "#our model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(256, 256, 1), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='softmax'))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "history = model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=120, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 5.8329 - acc: 0.0501 - val_loss: 3.3947 - val_acc: 0.0510\n",
      "Epoch 2/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 3.4742 - acc: 0.0449 - val_loss: 3.3427 - val_acc: 0.0510\n",
      "Epoch 3/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 3.4401 - acc: 0.0666 - val_loss: 3.3370 - val_acc: 0.0969\n",
      "Epoch 4/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 3.3940 - acc: 0.0520 - val_loss: 3.2842 - val_acc: 0.0867\n",
      "Epoch 5/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 3.3301 - acc: 0.0573 - val_loss: 3.2373 - val_acc: 0.0510\n",
      "Epoch 6/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 3.3116 - acc: 0.0772 - val_loss: 3.1545 - val_acc: 0.0867\n",
      "Epoch 7/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 3.1769 - acc: 0.1003 - val_loss: 3.0291 - val_acc: 0.0816\n",
      "Epoch 8/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 3.1227 - acc: 0.0962 - val_loss: 2.8670 - val_acc: 0.1122\n",
      "Epoch 9/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 2.9266 - acc: 0.1302 - val_loss: 2.7762 - val_acc: 0.1582\n",
      "Epoch 10/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 2.8030 - acc: 0.1616 - val_loss: 2.6503 - val_acc: 0.1735\n",
      "Epoch 11/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 2.7121 - acc: 0.1614 - val_loss: 2.5012 - val_acc: 0.2245\n",
      "Epoch 12/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 2.5466 - acc: 0.1944 - val_loss: 2.3711 - val_acc: 0.2296\n",
      "Epoch 13/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 2.4935 - acc: 0.1943 - val_loss: 2.2806 - val_acc: 0.2551\n",
      "Epoch 14/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 2.3680 - acc: 0.2256 - val_loss: 2.1781 - val_acc: 0.2704\n",
      "Epoch 15/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 2.2494 - acc: 0.2517 - val_loss: 2.0659 - val_acc: 0.2602\n",
      "Epoch 16/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 2.1983 - acc: 0.2401 - val_loss: 1.9905 - val_acc: 0.3112\n",
      "Epoch 17/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 2.0707 - acc: 0.2941 - val_loss: 1.9013 - val_acc: 0.2959\n",
      "Epoch 18/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 2.0146 - acc: 0.2868 - val_loss: 1.7912 - val_acc: 0.2908\n",
      "Epoch 19/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.9260 - acc: 0.3003 - val_loss: 1.7724 - val_acc: 0.3112\n",
      "Epoch 20/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.8772 - acc: 0.3227 - val_loss: 1.6786 - val_acc: 0.3724\n",
      "Epoch 21/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.8193 - acc: 0.3273 - val_loss: 1.6226 - val_acc: 0.3520\n",
      "Epoch 22/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.7385 - acc: 0.3478 - val_loss: 1.5790 - val_acc: 0.3878\n",
      "Epoch 23/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.6649 - acc: 0.3707 - val_loss: 1.4900 - val_acc: 0.3673\n",
      "Epoch 24/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.5526 - acc: 0.3819 - val_loss: 1.4694 - val_acc: 0.3929\n",
      "Epoch 25/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.5579 - acc: 0.4217 - val_loss: 1.4356 - val_acc: 0.4082\n",
      "Epoch 26/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.4792 - acc: 0.4411 - val_loss: 1.4072 - val_acc: 0.4490\n",
      "Epoch 27/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.4424 - acc: 0.4621 - val_loss: 1.3973 - val_acc: 0.4490\n",
      "Epoch 28/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.4085 - acc: 0.4587 - val_loss: 1.3135 - val_acc: 0.4796\n",
      "Epoch 29/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.3248 - acc: 0.4773 - val_loss: 1.2547 - val_acc: 0.4541\n",
      "Epoch 30/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.2881 - acc: 0.5271 - val_loss: 1.2223 - val_acc: 0.4949\n",
      "Epoch 31/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.2759 - acc: 0.5052 - val_loss: 1.2180 - val_acc: 0.4796\n",
      "Epoch 32/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.2011 - acc: 0.5250 - val_loss: 1.2445 - val_acc: 0.4388\n",
      "Epoch 33/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.2005 - acc: 0.5191 - val_loss: 1.1520 - val_acc: 0.5561\n",
      "Epoch 34/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.2064 - acc: 0.5330 - val_loss: 1.1263 - val_acc: 0.5357\n",
      "Epoch 35/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.1084 - acc: 0.5804 - val_loss: 1.1240 - val_acc: 0.5306\n",
      "Epoch 36/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.0705 - acc: 0.6061 - val_loss: 1.0767 - val_acc: 0.5918\n",
      "Epoch 37/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 1.0213 - acc: 0.6067 - val_loss: 1.1167 - val_acc: 0.5459\n",
      "Epoch 38/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 1.0253 - acc: 0.5889 - val_loss: 1.0510 - val_acc: 0.5969\n",
      "Epoch 39/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.9874 - acc: 0.6210 - val_loss: 1.0123 - val_acc: 0.5918\n",
      "Epoch 40/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.9419 - acc: 0.6340 - val_loss: 0.9664 - val_acc: 0.6633\n",
      "Epoch 41/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.9224 - acc: 0.6462 - val_loss: 0.9717 - val_acc: 0.6786\n",
      "Epoch 42/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.9188 - acc: 0.6321 - val_loss: 0.9583 - val_acc: 0.6480\n",
      "Epoch 43/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.8803 - acc: 0.6494 - val_loss: 0.9263 - val_acc: 0.6582\n",
      "Epoch 44/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.8507 - acc: 0.6808 - val_loss: 1.0018 - val_acc: 0.6480\n",
      "Epoch 45/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.8210 - acc: 0.6934 - val_loss: 0.9233 - val_acc: 0.7041\n",
      "Epoch 46/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.7733 - acc: 0.7262 - val_loss: 0.9277 - val_acc: 0.6735\n",
      "Epoch 47/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.7731 - acc: 0.7003 - val_loss: 0.8962 - val_acc: 0.6684\n",
      "Epoch 48/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.7688 - acc: 0.7213 - val_loss: 0.8527 - val_acc: 0.6990\n",
      "Epoch 49/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.7461 - acc: 0.7021 - val_loss: 0.8325 - val_acc: 0.7347\n",
      "Epoch 50/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.6767 - acc: 0.7585 - val_loss: 0.8329 - val_acc: 0.7194\n",
      "Epoch 51/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.6750 - acc: 0.7381 - val_loss: 0.8001 - val_acc: 0.7551\n",
      "Epoch 52/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.6236 - acc: 0.7709 - val_loss: 0.8296 - val_acc: 0.6837\n",
      "Epoch 53/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.6364 - acc: 0.7610 - val_loss: 0.8015 - val_acc: 0.7296\n",
      "Epoch 54/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.6064 - acc: 0.7908 - val_loss: 0.7864 - val_acc: 0.7296\n",
      "Epoch 55/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.5770 - acc: 0.7954 - val_loss: 0.7480 - val_acc: 0.7245\n",
      "Epoch 56/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.5568 - acc: 0.8194 - val_loss: 0.7779 - val_acc: 0.7143\n",
      "Epoch 57/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.5720 - acc: 0.7920 - val_loss: 0.7325 - val_acc: 0.7602\n",
      "Epoch 58/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.5346 - acc: 0.8015 - val_loss: 0.7290 - val_acc: 0.7296\n",
      "Epoch 59/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.5122 - acc: 0.8132 - val_loss: 0.7165 - val_acc: 0.7449\n",
      "Epoch 60/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.5116 - acc: 0.8221 - val_loss: 0.7132 - val_acc: 0.7602\n",
      "Epoch 61/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.5095 - acc: 0.8181 - val_loss: 0.7136 - val_acc: 0.7398\n",
      "Epoch 62/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 6s 57ms/step - loss: 0.4374 - acc: 0.8534 - val_loss: 0.7146 - val_acc: 0.7653\n",
      "Epoch 63/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.4108 - acc: 0.8586 - val_loss: 0.7042 - val_acc: 0.7755\n",
      "Epoch 64/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.4252 - acc: 0.8567 - val_loss: 0.7242 - val_acc: 0.7194\n",
      "Epoch 65/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.4207 - acc: 0.8614 - val_loss: 0.7299 - val_acc: 0.7296\n",
      "Epoch 66/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.4020 - acc: 0.8727 - val_loss: 0.6450 - val_acc: 0.7347\n",
      "Epoch 67/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 0.3908 - acc: 0.8651 - val_loss: 0.6791 - val_acc: 0.7449\n",
      "Epoch 68/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.3636 - acc: 0.8674 - val_loss: 0.6776 - val_acc: 0.7704\n",
      "Epoch 69/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.3661 - acc: 0.8883 - val_loss: 0.6074 - val_acc: 0.7755\n",
      "Epoch 70/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.3499 - acc: 0.8809 - val_loss: 0.6466 - val_acc: 0.7449\n",
      "Epoch 71/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.3501 - acc: 0.8782 - val_loss: 0.6024 - val_acc: 0.7704\n",
      "Epoch 72/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.3404 - acc: 0.8999 - val_loss: 0.6500 - val_acc: 0.7755\n",
      "Epoch 73/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.3239 - acc: 0.8938 - val_loss: 0.6400 - val_acc: 0.7704\n",
      "Epoch 74/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.3100 - acc: 0.9105 - val_loss: 0.6815 - val_acc: 0.7398\n",
      "Epoch 75/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.2905 - acc: 0.8951 - val_loss: 0.6237 - val_acc: 0.7449\n",
      "Epoch 76/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 0.2807 - acc: 0.9103 - val_loss: 0.6509 - val_acc: 0.7347\n",
      "Epoch 77/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.2606 - acc: 0.9177 - val_loss: 0.6464 - val_acc: 0.7551\n",
      "Epoch 78/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 0.2564 - acc: 0.9214 - val_loss: 0.6583 - val_acc: 0.7449\n",
      "Epoch 79/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.2554 - acc: 0.9230 - val_loss: 0.6739 - val_acc: 0.7857\n",
      "Epoch 80/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.2326 - acc: 0.9191 - val_loss: 0.6880 - val_acc: 0.7704\n",
      "Epoch 81/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.2354 - acc: 0.9346 - val_loss: 0.6396 - val_acc: 0.7653\n",
      "Epoch 82/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.2457 - acc: 0.9214 - val_loss: 0.6476 - val_acc: 0.7194\n",
      "Epoch 83/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.2175 - acc: 0.9385 - val_loss: 0.6405 - val_acc: 0.7551\n",
      "Epoch 84/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 0.2076 - acc: 0.9414 - val_loss: 0.6239 - val_acc: 0.7704\n",
      "Epoch 85/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 0.2155 - acc: 0.9355 - val_loss: 0.6401 - val_acc: 0.7653\n",
      "Epoch 86/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 0.1932 - acc: 0.9473 - val_loss: 0.6465 - val_acc: 0.7500\n",
      "Epoch 87/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1945 - acc: 0.9499 - val_loss: 0.6029 - val_acc: 0.7755\n",
      "Epoch 88/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1846 - acc: 0.9407 - val_loss: 0.6726 - val_acc: 0.7806\n",
      "Epoch 89/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1865 - acc: 0.9441 - val_loss: 0.7047 - val_acc: 0.7602\n",
      "Epoch 90/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 0.1814 - acc: 0.9474 - val_loss: 0.6712 - val_acc: 0.7551\n",
      "Epoch 91/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 0.1544 - acc: 0.9607 - val_loss: 0.6860 - val_acc: 0.7449\n",
      "Epoch 92/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1567 - acc: 0.9506 - val_loss: 0.6145 - val_acc: 0.7551\n",
      "Epoch 93/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1708 - acc: 0.9485 - val_loss: 0.6044 - val_acc: 0.7755\n",
      "Epoch 94/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1522 - acc: 0.9504 - val_loss: 0.6742 - val_acc: 0.7449\n",
      "Epoch 95/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1396 - acc: 0.9650 - val_loss: 0.6134 - val_acc: 0.7857\n",
      "Epoch 96/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1487 - acc: 0.9611 - val_loss: 0.6727 - val_acc: 0.7704\n",
      "Epoch 97/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1659 - acc: 0.9425 - val_loss: 0.5990 - val_acc: 0.7857\n",
      "Epoch 98/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 0.1182 - acc: 0.9657 - val_loss: 0.6066 - val_acc: 0.7500\n",
      "Epoch 99/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1393 - acc: 0.9574 - val_loss: 0.6136 - val_acc: 0.7602\n",
      "Epoch 100/120\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 0.1448 - acc: 0.9543 - val_loss: 0.6249 - val_acc: 0.7449\n",
      "Epoch 101/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0995 - acc: 0.9760 - val_loss: 0.6498 - val_acc: 0.7602\n",
      "Epoch 102/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1148 - acc: 0.9706 - val_loss: 0.6099 - val_acc: 0.7602\n",
      "Epoch 103/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1181 - acc: 0.9742 - val_loss: 0.6154 - val_acc: 0.7704\n",
      "Epoch 104/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1187 - acc: 0.9657 - val_loss: 0.6577 - val_acc: 0.7398\n",
      "Epoch 105/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1099 - acc: 0.9720 - val_loss: 0.6314 - val_acc: 0.7602\n",
      "Epoch 106/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1014 - acc: 0.9761 - val_loss: 0.6935 - val_acc: 0.7143\n",
      "Epoch 107/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1107 - acc: 0.9706 - val_loss: 0.6123 - val_acc: 0.7551\n",
      "Epoch 108/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1009 - acc: 0.9761 - val_loss: 0.6472 - val_acc: 0.7755\n",
      "Epoch 109/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.1202 - acc: 0.9606 - val_loss: 0.7145 - val_acc: 0.7500\n",
      "Epoch 110/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0955 - acc: 0.9776 - val_loss: 0.6567 - val_acc: 0.7908\n",
      "Epoch 111/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0852 - acc: 0.9825 - val_loss: 0.7507 - val_acc: 0.7449\n",
      "Epoch 112/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0962 - acc: 0.9646 - val_loss: 0.7300 - val_acc: 0.7500\n",
      "Epoch 113/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0840 - acc: 0.9785 - val_loss: 0.6708 - val_acc: 0.7653\n",
      "Epoch 114/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0953 - acc: 0.9778 - val_loss: 0.7522 - val_acc: 0.7245\n",
      "Epoch 115/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0954 - acc: 0.9720 - val_loss: 0.7259 - val_acc: 0.7551\n",
      "Epoch 116/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0830 - acc: 0.9750 - val_loss: 0.7159 - val_acc: 0.7653\n",
      "Epoch 117/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0693 - acc: 0.9844 - val_loss: 0.7397 - val_acc: 0.7551\n",
      "Epoch 118/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0720 - acc: 0.9789 - val_loss: 0.7601 - val_acc: 0.7500\n",
      "Epoch 119/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0759 - acc: 0.9756 - val_loss: 0.7580 - val_acc: 0.7449\n",
      "Epoch 120/120\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 0.0770 - acc: 0.9801 - val_loss: 0.7852 - val_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "A_num = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        #if(float(item.split('_')[0].split('w')[0].split('A')[1]) == 300):\n",
    "        if(str(item.split('_')[1]) != 'HShen' and str(item.split('_')[1]) != 'HShenH'):\n",
    "            A_num.append(index)\n",
    "    index+=1\n",
    "#get the label of w.\n",
    "y_train = []\n",
    "y_test = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        if(index in A_num):\n",
    "            y_train.append(float(item.split('_')[0].split('w')[1]))\n",
    "        else:\n",
    "            y_test.append(float(item.split('_')[0].split('w')[1]))\n",
    "    index += 1\n",
    "#read image data.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "X_train = []\n",
    "X_test = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        if(index in A_num):\n",
    "            #for j in range(5):\n",
    "                #title = 'Final_EOS/'+ str(index) + \"_\" + str(j) + '.jpeg' \n",
    "            title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "            image = Image.open(title).convert('L')\n",
    "            X_train.append(np.array(image))\n",
    "        else:\n",
    "            title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "            image = Image.open(title).convert('L')\n",
    "            X_test.append(np.array(image))\n",
    "    index += 1\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_train = X_train.reshape(X_train.shape[0], 256, 256, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 256, 256, 1)\n",
    "#using one hot to encode the label.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "#our model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(256, 256, 1), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='softmax'))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "history = model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=120, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "46/46 [==============================] - 6s 132ms/step - loss: 7.7074 - acc: 0.0285 - val_loss: 3.3865 - val_acc: 0.0515\n",
      "Epoch 2/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 3.7944 - acc: 0.0453 - val_loss: 3.3666 - val_acc: 0.0515\n",
      "Epoch 3/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 3.5371 - acc: 0.0466 - val_loss: 3.3315 - val_acc: 0.0515\n",
      "Epoch 4/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 3.4397 - acc: 0.0573 - val_loss: 3.3091 - val_acc: 0.0515\n",
      "Epoch 5/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 3.3983 - acc: 0.0462 - val_loss: 3.3094 - val_acc: 0.0515\n",
      "Epoch 6/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 3.4057 - acc: 0.0585 - val_loss: 3.2820 - val_acc: 0.1029\n",
      "Epoch 7/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 3.3126 - acc: 0.0716 - val_loss: 3.2347 - val_acc: 0.0961\n",
      "Epoch 8/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 3.3220 - acc: 0.0654 - val_loss: 3.1760 - val_acc: 0.0825\n",
      "Epoch 9/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 3.2669 - acc: 0.0651 - val_loss: 3.1257 - val_acc: 0.1010\n",
      "Epoch 10/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 3.1796 - acc: 0.0865 - val_loss: 3.0782 - val_acc: 0.1010\n",
      "Epoch 11/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 3.0711 - acc: 0.1056 - val_loss: 2.9833 - val_acc: 0.1748\n",
      "Epoch 12/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 3.0744 - acc: 0.0928 - val_loss: 2.8708 - val_acc: 0.1165\n",
      "Epoch 13/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.9562 - acc: 0.1085 - val_loss: 2.8576 - val_acc: 0.1204\n",
      "Epoch 14/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.9479 - acc: 0.0917 - val_loss: 2.7776 - val_acc: 0.1670\n",
      "Epoch 15/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.9087 - acc: 0.1196 - val_loss: 2.6966 - val_acc: 0.1990\n",
      "Epoch 16/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.7597 - acc: 0.1436 - val_loss: 2.6429 - val_acc: 0.1641\n",
      "Epoch 17/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.6892 - acc: 0.1584 - val_loss: 2.5978 - val_acc: 0.1903\n",
      "Epoch 18/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.6191 - acc: 0.1757 - val_loss: 2.5382 - val_acc: 0.2136\n",
      "Epoch 19/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.5657 - acc: 0.1865 - val_loss: 2.5203 - val_acc: 0.2194\n",
      "Epoch 20/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.5525 - acc: 0.1745 - val_loss: 2.4429 - val_acc: 0.2146\n",
      "Epoch 21/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 2.4999 - acc: 0.1977 - val_loss: 2.4239 - val_acc: 0.2078\n",
      "Epoch 22/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.4783 - acc: 0.2068 - val_loss: 2.3541 - val_acc: 0.2223\n",
      "Epoch 23/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.4232 - acc: 0.2193 - val_loss: 2.3216 - val_acc: 0.2272\n",
      "Epoch 24/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.3671 - acc: 0.2201 - val_loss: 2.2700 - val_acc: 0.2029\n",
      "Epoch 25/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.3377 - acc: 0.2142 - val_loss: 2.2540 - val_acc: 0.2495\n",
      "Epoch 26/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.2656 - acc: 0.2251 - val_loss: 2.1784 - val_acc: 0.2767\n",
      "Epoch 27/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.1903 - acc: 0.2791 - val_loss: 2.1648 - val_acc: 0.2602\n",
      "Epoch 28/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.2136 - acc: 0.2691 - val_loss: 2.1836 - val_acc: 0.2447\n",
      "Epoch 29/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.1859 - acc: 0.2487 - val_loss: 2.1118 - val_acc: 0.3039\n",
      "Epoch 30/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.1749 - acc: 0.2598 - val_loss: 2.0688 - val_acc: 0.3019\n",
      "Epoch 31/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.1343 - acc: 0.2369 - val_loss: 2.0947 - val_acc: 0.2854\n",
      "Epoch 32/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.0775 - acc: 0.2993 - val_loss: 2.0615 - val_acc: 0.3000\n",
      "Epoch 33/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.0366 - acc: 0.2923 - val_loss: 2.0168 - val_acc: 0.2942\n",
      "Epoch 34/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.0508 - acc: 0.2435 - val_loss: 1.9866 - val_acc: 0.2922\n",
      "Epoch 35/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.9060 - acc: 0.3362 - val_loss: 1.9605 - val_acc: 0.2951\n",
      "Epoch 36/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.0568 - acc: 0.2781 - val_loss: 1.9432 - val_acc: 0.2670\n",
      "Epoch 37/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 2.0081 - acc: 0.2769 - val_loss: 1.8680 - val_acc: 0.3495\n",
      "Epoch 38/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 1.8569 - acc: 0.3434 - val_loss: 1.8374 - val_acc: 0.3466\n",
      "Epoch 39/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.8074 - acc: 0.3563 - val_loss: 1.8148 - val_acc: 0.3417\n",
      "Epoch 40/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.7375 - acc: 0.3637 - val_loss: 1.7763 - val_acc: 0.3631\n",
      "Epoch 41/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.7644 - acc: 0.3667 - val_loss: 1.7561 - val_acc: 0.3524\n",
      "Epoch 42/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.6974 - acc: 0.3732 - val_loss: 1.7023 - val_acc: 0.3903\n",
      "Epoch 43/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.6134 - acc: 0.4058 - val_loss: 1.7160 - val_acc: 0.3340\n",
      "Epoch 44/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.6751 - acc: 0.4171 - val_loss: 1.7034 - val_acc: 0.3515\n",
      "Epoch 45/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.5822 - acc: 0.4499 - val_loss: 1.6443 - val_acc: 0.3845\n",
      "Epoch 46/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.5696 - acc: 0.4020 - val_loss: 1.6568 - val_acc: 0.3612\n",
      "Epoch 47/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.5629 - acc: 0.4117 - val_loss: 1.6407 - val_acc: 0.3680\n",
      "Epoch 48/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.4483 - acc: 0.4626 - val_loss: 1.6043 - val_acc: 0.3738\n",
      "Epoch 49/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.4477 - acc: 0.4532 - val_loss: 1.6007 - val_acc: 0.3621\n",
      "Epoch 50/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.4549 - acc: 0.4535 - val_loss: 1.5678 - val_acc: 0.4117\n",
      "Epoch 51/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.3611 - acc: 0.5044 - val_loss: 1.5849 - val_acc: 0.3592\n",
      "Epoch 52/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.3290 - acc: 0.4973 - val_loss: 1.5652 - val_acc: 0.3864\n",
      "Epoch 53/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.3311 - acc: 0.4928 - val_loss: 1.4964 - val_acc: 0.3942\n",
      "Epoch 54/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.3604 - acc: 0.4692 - val_loss: 1.5426 - val_acc: 0.4437\n",
      "Epoch 55/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.2789 - acc: 0.5427 - val_loss: 1.6310 - val_acc: 0.3476\n",
      "Epoch 56/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.2498 - acc: 0.5631 - val_loss: 1.4601 - val_acc: 0.4398\n",
      "Epoch 57/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.2020 - acc: 0.5270 - val_loss: 1.4745 - val_acc: 0.4330\n",
      "Epoch 58/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.2340 - acc: 0.5377 - val_loss: 1.4618 - val_acc: 0.4155\n",
      "Epoch 59/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 1.1860 - acc: 0.5306 - val_loss: 1.4974 - val_acc: 0.4049\n",
      "Epoch 60/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.1585 - acc: 0.5797 - val_loss: 1.5511 - val_acc: 0.4204\n",
      "Epoch 61/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.1161 - acc: 0.5650 - val_loss: 1.4491 - val_acc: 0.4388\n",
      "Epoch 62/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 4s 85ms/step - loss: 1.1289 - acc: 0.5813 - val_loss: 1.4829 - val_acc: 0.4544\n",
      "Epoch 63/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.1468 - acc: 0.5552 - val_loss: 1.4481 - val_acc: 0.4456\n",
      "Epoch 64/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.0391 - acc: 0.6055 - val_loss: 1.4570 - val_acc: 0.4466\n",
      "Epoch 65/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 1.0311 - acc: 0.6336 - val_loss: 1.3673 - val_acc: 0.4903\n",
      "Epoch 66/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.9834 - acc: 0.6304 - val_loss: 1.3625 - val_acc: 0.4942\n",
      "Epoch 67/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.9614 - acc: 0.6457 - val_loss: 1.3987 - val_acc: 0.4709\n",
      "Epoch 68/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.9732 - acc: 0.6452 - val_loss: 1.3653 - val_acc: 0.4903\n",
      "Epoch 69/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.9380 - acc: 0.6404 - val_loss: 1.3887 - val_acc: 0.4718\n",
      "Epoch 70/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.8882 - acc: 0.6781 - val_loss: 1.3457 - val_acc: 0.4650\n",
      "Epoch 71/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.8830 - acc: 0.6969 - val_loss: 1.3550 - val_acc: 0.4680\n",
      "Epoch 72/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.8624 - acc: 0.6696 - val_loss: 1.3596 - val_acc: 0.4699\n",
      "Epoch 73/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.8538 - acc: 0.6897 - val_loss: 1.3495 - val_acc: 0.4796\n",
      "Epoch 74/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.8914 - acc: 0.6617 - val_loss: 1.3215 - val_acc: 0.4786\n",
      "Epoch 75/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.8431 - acc: 0.6782 - val_loss: 1.3730 - val_acc: 0.4680\n",
      "Epoch 76/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.8014 - acc: 0.7205 - val_loss: 1.3022 - val_acc: 0.5000\n",
      "Epoch 77/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.8047 - acc: 0.7059 - val_loss: 1.4185 - val_acc: 0.4680\n",
      "Epoch 78/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.7569 - acc: 0.7317 - val_loss: 1.3460 - val_acc: 0.5175\n",
      "Epoch 79/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.7531 - acc: 0.7133 - val_loss: 1.3586 - val_acc: 0.5049\n",
      "Epoch 80/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.7545 - acc: 0.7512 - val_loss: 1.2953 - val_acc: 0.4767\n",
      "Epoch 81/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.7744 - acc: 0.6989 - val_loss: 1.2907 - val_acc: 0.4971\n",
      "Epoch 82/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.6748 - acc: 0.7533 - val_loss: 1.2750 - val_acc: 0.5165\n",
      "Epoch 83/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.6977 - acc: 0.7559 - val_loss: 1.2654 - val_acc: 0.4981\n",
      "Epoch 84/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 0.6284 - acc: 0.7804 - val_loss: 1.4629 - val_acc: 0.4748\n",
      "Epoch 85/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.6858 - acc: 0.7825 - val_loss: 1.3043 - val_acc: 0.4932\n",
      "Epoch 86/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.6504 - acc: 0.7733 - val_loss: 1.2806 - val_acc: 0.4913\n",
      "Epoch 87/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.5851 - acc: 0.8087 - val_loss: 1.3639 - val_acc: 0.5000\n",
      "Epoch 88/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.6743 - acc: 0.7564 - val_loss: 1.3517 - val_acc: 0.4728\n",
      "Epoch 89/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.6097 - acc: 0.7900 - val_loss: 1.3128 - val_acc: 0.5097\n",
      "Epoch 90/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 0.6482 - acc: 0.7493 - val_loss: 1.3163 - val_acc: 0.5000\n",
      "Epoch 91/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.5830 - acc: 0.8085 - val_loss: 1.2763 - val_acc: 0.5165\n",
      "Epoch 92/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.5798 - acc: 0.8142 - val_loss: 1.3387 - val_acc: 0.4786\n",
      "Epoch 93/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.5783 - acc: 0.8056 - val_loss: 1.2949 - val_acc: 0.5068\n",
      "Epoch 94/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 0.5249 - acc: 0.8195 - val_loss: 1.2578 - val_acc: 0.5146\n",
      "Epoch 95/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.5203 - acc: 0.8176 - val_loss: 1.2745 - val_acc: 0.5282\n",
      "Epoch 96/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.5122 - acc: 0.8277 - val_loss: 1.2970 - val_acc: 0.5155\n",
      "Epoch 97/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.4909 - acc: 0.8513 - val_loss: 1.3253 - val_acc: 0.5194\n",
      "Epoch 98/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.4982 - acc: 0.8253 - val_loss: 1.3525 - val_acc: 0.5000\n",
      "Epoch 99/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 0.4872 - acc: 0.8305 - val_loss: 1.2778 - val_acc: 0.5301\n",
      "Epoch 100/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.4459 - acc: 0.8634 - val_loss: 1.2479 - val_acc: 0.5320\n",
      "Epoch 101/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.4621 - acc: 0.8530 - val_loss: 1.3307 - val_acc: 0.5272\n",
      "Epoch 102/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.4551 - acc: 0.8208 - val_loss: 1.2999 - val_acc: 0.5427\n",
      "Epoch 103/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.4499 - acc: 0.8480 - val_loss: 1.3936 - val_acc: 0.5117\n",
      "Epoch 104/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.4450 - acc: 0.8626 - val_loss: 1.3144 - val_acc: 0.5165\n",
      "Epoch 105/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 0.4347 - acc: 0.8523 - val_loss: 1.2730 - val_acc: 0.5252\n",
      "Epoch 106/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.4224 - acc: 0.8779 - val_loss: 1.3562 - val_acc: 0.5311\n",
      "Epoch 107/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.4053 - acc: 0.8672 - val_loss: 1.3396 - val_acc: 0.5427\n",
      "Epoch 108/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 0.3866 - acc: 0.8748 - val_loss: 1.2995 - val_acc: 0.5243\n",
      "Epoch 109/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.3415 - acc: 0.8960 - val_loss: 1.3161 - val_acc: 0.5087\n",
      "Epoch 110/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.3717 - acc: 0.8920 - val_loss: 1.3440 - val_acc: 0.5117\n",
      "Epoch 111/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.3631 - acc: 0.8757 - val_loss: 1.2969 - val_acc: 0.5408\n",
      "Epoch 112/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.3346 - acc: 0.8854 - val_loss: 1.2563 - val_acc: 0.5466\n",
      "Epoch 113/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.3667 - acc: 0.8913 - val_loss: 1.3763 - val_acc: 0.5126\n",
      "Epoch 114/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.3223 - acc: 0.8881 - val_loss: 1.2541 - val_acc: 0.5447\n",
      "Epoch 115/120\n",
      "46/46 [==============================] - 4s 84ms/step - loss: 0.3052 - acc: 0.9134 - val_loss: 1.2965 - val_acc: 0.5311\n",
      "Epoch 116/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.3290 - acc: 0.8991 - val_loss: 1.3206 - val_acc: 0.5320\n",
      "Epoch 117/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2815 - acc: 0.9187 - val_loss: 1.3185 - val_acc: 0.5369\n",
      "Epoch 118/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.3099 - acc: 0.9053 - val_loss: 1.3035 - val_acc: 0.5398\n",
      "Epoch 119/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.3054 - acc: 0.9019 - val_loss: 1.3056 - val_acc: 0.5485\n",
      "Epoch 120/120\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2967 - acc: 0.9178 - val_loss: 1.3658 - val_acc: 0.5136\n"
     ]
    }
   ],
   "source": [
    "A_num = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        #if(float(item.split('_')[0].split('w')[0].split('A')[1]) == 300):\n",
    "        if(str(item.split('_')[1]) != 'HSDD2' and str(item.split('_')[1]) != 'HSFSG' and\n",
    "          str(item.split('_')[1]) != 'HSIUF' and str(item.split('_')[1]) != 'HSNL3' and\n",
    "          str(item.split('_')[1]) != 'HSTM1' and str(item.split('_')[1]) != 'HSTMA' and\n",
    "          str(item.split('_')[1]) != 'SFHo' and str(item.split('_')[1]) != 'SFHx' and\n",
    "          str(item.split('_')[1]) != 'BHBL' and str(item.split('_')[1]) != 'BHBLP'):\n",
    "            A_num.append(index)\n",
    "    index+=1\n",
    "#get the label of w.\n",
    "y_train = []\n",
    "y_test = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        if(index in A_num):\n",
    "            y_train.append(float(item.split('_')[0].split('w')[1]))\n",
    "        else:\n",
    "            y_test.append(float(item.split('_')[0].split('w')[1]))\n",
    "    index += 1\n",
    "#read image data.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "X_train = []\n",
    "X_test = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        if(index in A_num):\n",
    "            #for j in range(5):\n",
    "                #title = 'Final_EOS/'+ str(index) + \"_\" + str(j) + '.jpeg' \n",
    "            title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "            image = Image.open(title).convert('L')\n",
    "            X_train.append(np.array(image))\n",
    "        else:\n",
    "            title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "            image = Image.open(title).convert('L')\n",
    "            X_test.append(np.array(image))\n",
    "    index += 1\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_train = X_train.reshape(X_train.shape[0], 256, 256, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 256, 256, 1)\n",
    "#using one hot to encode the label.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "#our model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(256, 256, 1), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='softmax'))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "history = model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=120, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.2684 - acc: 0.9237 - val_loss: 1.4175 - val_acc: 0.5252\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2951 - acc: 0.9101 - val_loss: 1.3319 - val_acc: 0.5534\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2817 - acc: 0.9169 - val_loss: 1.3697 - val_acc: 0.5340\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2502 - acc: 0.9223 - val_loss: 1.3823 - val_acc: 0.5223\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2541 - acc: 0.9305 - val_loss: 1.4684 - val_acc: 0.5039\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.2619 - acc: 0.9155 - val_loss: 1.2990 - val_acc: 0.5680\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2556 - acc: 0.9237 - val_loss: 1.3244 - val_acc: 0.5252\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2538 - acc: 0.9251 - val_loss: 1.3382 - val_acc: 0.5563\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2409 - acc: 0.9346 - val_loss: 1.3358 - val_acc: 0.5485\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2188 - acc: 0.9319 - val_loss: 1.3427 - val_acc: 0.5592\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2386 - acc: 0.9332 - val_loss: 1.3404 - val_acc: 0.5417\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.1988 - acc: 0.9550 - val_loss: 1.3425 - val_acc: 0.5476\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2055 - acc: 0.9455 - val_loss: 1.3081 - val_acc: 0.5544\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2195 - acc: 0.9305 - val_loss: 1.3794 - val_acc: 0.5544\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2061 - acc: 0.9360 - val_loss: 1.3212 - val_acc: 0.5612\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.2097 - acc: 0.9264 - val_loss: 1.3372 - val_acc: 0.5573\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1990 - acc: 0.9496 - val_loss: 1.3714 - val_acc: 0.5553\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1837 - acc: 0.9510 - val_loss: 1.3750 - val_acc: 0.5592\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1858 - acc: 0.9469 - val_loss: 1.3743 - val_acc: 0.5699\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1883 - acc: 0.9482 - val_loss: 1.4295 - val_acc: 0.5505\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.1791 - acc: 0.9550 - val_loss: 1.4258 - val_acc: 0.5524\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1792 - acc: 0.9496 - val_loss: 1.5219 - val_acc: 0.5447\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.1702 - acc: 0.9619 - val_loss: 1.4904 - val_acc: 0.5456\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1787 - acc: 0.9469 - val_loss: 1.3935 - val_acc: 0.5563\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1683 - acc: 0.9564 - val_loss: 1.4165 - val_acc: 0.5670\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 4s 85ms/step - loss: 0.1872 - acc: 0.9510 - val_loss: 1.5560 - val_acc: 0.5534\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1982 - acc: 0.9292 - val_loss: 1.4965 - val_acc: 0.5398\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1548 - acc: 0.9578 - val_loss: 1.3618 - val_acc: 0.5631\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1398 - acc: 0.9646 - val_loss: 1.3895 - val_acc: 0.5932\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.1588 - acc: 0.9632 - val_loss: 1.3898 - val_acc: 0.5650\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=30, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
