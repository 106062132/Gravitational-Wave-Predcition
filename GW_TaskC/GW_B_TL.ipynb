{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If using GPU.\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['reduced_data', 'waveforms', 'yeofrho']>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read database.\n",
    "f = h5py.File('GWdatabase.h5','r')   \n",
    "f.keys()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list that contains all the failure cases.\n",
    "fail_num = []\n",
    "index = 0\n",
    "for item in f['reduced_data']['tbounce(s)']:\n",
    "    if(item == -1):\n",
    "        fail_num.append(index)\n",
    "    index += 1\n",
    "fail_case = []\n",
    "for index in fail_num:\n",
    "    fail_case.append([f['reduced_data']['A(km)'][index],f['reduced_data']['omega_0(rad|s)'][index],f['reduced_data']['EOS'][index]])\n",
    "fail_list= []\n",
    "for item in fail_case:\n",
    "    tmp = str(item[2]).split(\"b'\")[1].split(\"'\")[0]\n",
    "    tmp = \"A\" + str(int(item[0])) + \"w\" + str(item[1]) + \"0_\" + tmp\n",
    "    fail_list.append(tmp)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose which label we want to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the label of w.\n",
    "labels = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        labels.append(float(item.split('_')[0].split('w')[1]))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image data.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "data = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "        image = Image.open(title).convert('L')\n",
    "        data.append(np.array(image))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd0b0e42f40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 256x256 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the data.\n",
    "plt.figure(figsize=(4, 4), dpi=64)\n",
    "plt.imshow(data[5], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the data type to numpy array\n",
    "data = np.array(data)\n",
    "X_train = data\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "#from keras.utils import np_utilsy\n",
    "from keras import backend as K\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1764, 256, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer the data shape for model training\n",
    "X_train = X_train.reshape(X_train.shape[0], 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using one hot to encode the label.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = Sequential()\n",
    "model_encoder.add(Conv2D(64, (5, 5), input_shape=(256, 256, 1), padding=\"same\", activation='relu'))\n",
    "model_encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_encoder.add(Conv2D(128, (5, 5), padding=\"same\", activation='relu'))\n",
    "model_encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_encoder.add(Conv2D(256, (5, 5), padding=\"same\", activation='relu'))\n",
    "model_encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_encoder.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model_encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_encoder.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model_encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_encoder.add(Dropout(0.5))\n",
    "model_encoder.add(Flatten())\n",
    "model_decoder = Sequential()\n",
    "model_decoder.add(Dense(1024, activation='relu'))\n",
    "model_decoder.add(Dense(512, activation='relu'))\n",
    "model_decoder.add(Dense(128, activation='relu'))\n",
    "model_decoder.add(Dense(32, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(model_encoder)\n",
    "model_1.add(model_decoder)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "441/441 [==============================] - 17s 33ms/step - loss: 4.4818 - acc: 0.0443\n",
      "Epoch 2/40\n",
      "441/441 [==============================] - 15s 33ms/step - loss: 3.4164 - acc: 0.0375 0s - loss: 3.4172\n",
      "Epoch 3/40\n",
      "441/441 [==============================] - 15s 33ms/step - loss: 3.3478 - acc: 0.0585\n",
      "Epoch 4/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 3.2226 - acc: 0.0900\n",
      "Epoch 5/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 2.9095 - acc: 0.1412\n",
      "Epoch 6/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 2.5819 - acc: 0.1561\n",
      "Epoch 7/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 2.3369 - acc: 0.2247\n",
      "Epoch 8/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 2.1911 - acc: 0.2380\n",
      "Epoch 9/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 2.0552 - acc: 0.2639\n",
      "Epoch 10/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.9221 - acc: 0.2915 0s - loss: 1.9231\n",
      "Epoch 11/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.8035 - acc: 0.3327 1s - loss\n",
      "Epoch 12/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.7392 - acc: 0.3421 0s - loss: 1.7394 - acc: 0.34\n",
      "Epoch 13/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.6487 - acc: 0.3742\n",
      "Epoch 14/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.6031 - acc: 0.3905\n",
      "Epoch 15/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.4266 - acc: 0.4511\n",
      "Epoch 16/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.4296 - acc: 0.4310 4s - loss\n",
      "Epoch 17/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.3740 - acc: 0.4463 1s -\n",
      "Epoch 18/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.3299 - acc: 0.4681\n",
      "Epoch 19/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.2451 - acc: 0.5170\n",
      "Epoch 20/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.1882 - acc: 0.5252 0s - loss: 1.1882 - acc: 0.52\n",
      "Epoch 21/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.0989 - acc: 0.5391\n",
      "Epoch 22/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.0416 - acc: 0.5709\n",
      "Epoch 23/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.9862 - acc: 0.6076 0s - loss: 0.9854 -\n",
      "Epoch 24/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.9409 - acc: 0.6200\n",
      "Epoch 25/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.9340 - acc: 0.6234\n",
      "Epoch 26/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.8719 - acc: 0.6600\n",
      "Epoch 27/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.8058 - acc: 0.6746\n",
      "Epoch 28/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.7526 - acc: 0.7015\n",
      "Epoch 29/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.7233 - acc: 0.7231\n",
      "Epoch 30/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.7070 - acc: 0.7068\n",
      "Epoch 31/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.6343 - acc: 0.7784\n",
      "Epoch 32/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.6138 - acc: 0.7535\n",
      "Epoch 33/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.5993 - acc: 0.7767\n",
      "Epoch 34/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.5534 - acc: 0.8004\n",
      "Epoch 35/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.5289 - acc: 0.7877\n",
      "Epoch 36/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.4927 - acc: 0.8108\n",
      "Epoch 37/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.4739 - acc: 0.8209\n",
      "Epoch 38/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.4346 - acc: 0.8391\n",
      "Epoch 39/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.4049 - acc: 0.8512\n",
      "Epoch 40/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.4166 - acc: 0.8314\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(x=X_train, y=y_train, epochs=40, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the GPU is out of memory while testing, we may need to save the trained model, restart, then load the model. \n",
    "model_encoder.save('model_TL_encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_encoder = keras.models.load_model('model_TL_encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFER LEARNING\n",
    "a = []\n",
    "f = h5py.File('20210611.h5','r')   \n",
    "index = 0\n",
    "for item in f:\n",
    "    check = np.array(f[item])\n",
    "    if(check.size > 0):\n",
    "        if(float(item.split('w')[1]) < 6.1):\n",
    "            if(item.split('w')[0] != 'A634'):\n",
    "                a.append(index)\n",
    "            index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFER LEARNING\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "X_train = []\n",
    "X_test = []\n",
    "for i in range(60): \n",
    "    if(i in a):\n",
    "        title = 'test_new/'+ str(i) + '.jpeg'\n",
    "        image = Image.open(title).convert('L')\n",
    "        X_train.append(np.array(image))\n",
    "    else:\n",
    "        title = 'test_new/'+ str(i) + '.jpeg'\n",
    "        image = Image.open(title).convert('L')\n",
    "        X_test.append(np.array(image))\n",
    "y_train = []\n",
    "y_test = []\n",
    "f = h5py.File('20210611.h5','r')   \n",
    "index = 0\n",
    "for item in f:\n",
    "    check = np.array(f[item])\n",
    "    if(check.size > 0):\n",
    "        if(float(item.split('w')[1]) < 6.1):\n",
    "            if(index in a):\n",
    "                y_train.append(float(item.split('w')[1]))\n",
    "            else:\n",
    "                y_test.append(float(item.split('w')[1]))\n",
    "            index += 1\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 256, 256, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_decoder2 = Sequential()\n",
    "model_decoder2.add(Dense(1024, activation='relu'))\n",
    "model_decoder2.add(Dense(512, activation='relu'))\n",
    "model_decoder2.add(Dense(128, activation='relu'))\n",
    "model_decoder2.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder.trainable = True\n",
    "model_2 = Sequential()\n",
    "model_2.add(model_encoder)\n",
    "model_2.add(model_decoder2)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.000003)\n",
    "model_2.compile(loss='mse', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 40ms/step - loss: 0.2227 - mae: 0.3488 - val_loss: 0.1379 - val_mae: 0.2118\n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=100, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_2 = model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on Richar's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('GWdatabase.h5','r')  \n",
    "#get the label of w.\n",
    "labels = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        labels.append(float(item.split('_')[0].split('w')[1]))\n",
    "    index += 1\n",
    "#read image data.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "data = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "        image = Image.open(title).convert('L')\n",
    "        data.append(np.array(image))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the data type to numpy array\n",
    "data = np.array(data)\n",
    "X_train = data\n",
    "y_train = labels\n",
    "y_train = np.array(y_train)\n",
    "#transfer the data shape for model training\n",
    "X_train = X_train.reshape(X_train.shape[0], 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(256, 256, 1), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.000003)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "111/111 [==============================] - 8s 54ms/step - loss: 34.0673 - mae: 4.6114\n",
      "Epoch 2/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 20.9456 - mae: 3.6823\n",
      "Epoch 3/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 18.4016 - mae: 3.4382\n",
      "Epoch 4/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 14.9659 - mae: 3.1015\n",
      "Epoch 5/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 13.1375 - mae: 2.9350\n",
      "Epoch 6/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 11.9523 - mae: 2.7886\n",
      "Epoch 7/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 10.1003 - mae: 2.5248\n",
      "Epoch 8/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 7.1320 - mae: 2.0578\n",
      "Epoch 9/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 5.4531 - mae: 1.7894\n",
      "Epoch 10/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 4.3124 - mae: 1.5801\n",
      "Epoch 11/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 3.6123 - mae: 1.4827\n",
      "Epoch 12/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 3.3627 - mae: 1.4117\n",
      "Epoch 13/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 2.7380 - mae: 1.2893\n",
      "Epoch 14/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 2.6372 - mae: 1.2505\n",
      "Epoch 15/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 2.3533 - mae: 1.2047\n",
      "Epoch 16/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 2.0615 - mae: 1.1251\n",
      "Epoch 17/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.9210 - mae: 1.0854\n",
      "Epoch 18/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.8973 - mae: 1.0993\n",
      "Epoch 19/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.6912 - mae: 1.0279\n",
      "Epoch 20/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.5522 - mae: 0.9696\n",
      "Epoch 21/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.4100 - mae: 0.9274\n",
      "Epoch 22/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.2998 - mae: 0.8939\n",
      "Epoch 23/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.3887 - mae: 0.9225\n",
      "Epoch 24/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 1.2644 - mae: 0.8704\n",
      "Epoch 25/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 1.0898 - mae: 0.8212\n",
      "Epoch 26/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.1161 - mae: 0.8160\n",
      "Epoch 27/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 1.0290 - mae: 0.8031\n",
      "Epoch 28/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 1.0593 - mae: 0.8210\n",
      "Epoch 29/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.9195 - mae: 0.7585\n",
      "Epoch 30/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 1.0105 - mae: 0.7973\n",
      "Epoch 31/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.8969 - mae: 0.7601\n",
      "Epoch 32/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.9319 - mae: 0.7625\n",
      "Epoch 33/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.8384 - mae: 0.7241\n",
      "Epoch 34/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.8165 - mae: 0.7116\n",
      "Epoch 35/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.8176 - mae: 0.7162\n",
      "Epoch 36/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.8070 - mae: 0.6988\n",
      "Epoch 37/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.7411 - mae: 0.6897\n",
      "Epoch 38/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.7103 - mae: 0.6663\n",
      "Epoch 39/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6908 - mae: 0.6414\n",
      "Epoch 40/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5981 - mae: 0.6128\n",
      "Epoch 41/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6725 - mae: 0.6462\n",
      "Epoch 42/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6217 - mae: 0.6071\n",
      "Epoch 43/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6774 - mae: 0.6581\n",
      "Epoch 44/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6387 - mae: 0.6170\n",
      "Epoch 45/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5716 - mae: 0.5904\n",
      "Epoch 46/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6058 - mae: 0.6040\n",
      "Epoch 47/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5757 - mae: 0.5903\n",
      "Epoch 48/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5248 - mae: 0.5703\n",
      "Epoch 49/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.4899 - mae: 0.5473\n",
      "Epoch 50/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5065 - mae: 0.5650\n",
      "Epoch 51/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5031 - mae: 0.5587\n",
      "Epoch 52/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.4728 - mae: 0.5471\n",
      "Epoch 53/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4780 - mae: 0.5415\n",
      "Epoch 54/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4471 - mae: 0.5251\n",
      "Epoch 55/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4533 - mae: 0.5395\n",
      "Epoch 56/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4493 - mae: 0.5268\n",
      "Epoch 57/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4291 - mae: 0.5101\n",
      "Epoch 58/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4283 - mae: 0.5078\n",
      "Epoch 59/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4423 - mae: 0.5150\n",
      "Epoch 60/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4286 - mae: 0.5084\n",
      "Epoch 61/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4098 - mae: 0.4967\n",
      "Epoch 62/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3796 - mae: 0.4744\n",
      "Epoch 63/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3616 - mae: 0.4740\n",
      "Epoch 64/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3476 - mae: 0.4652\n",
      "Epoch 65/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3740 - mae: 0.4820\n",
      "Epoch 66/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3364 - mae: 0.4578\n",
      "Epoch 67/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3492 - mae: 0.4679\n",
      "Epoch 68/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3420 - mae: 0.4541\n",
      "Epoch 69/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3699 - mae: 0.4794\n",
      "Epoch 70/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3183 - mae: 0.4390\n",
      "Epoch 71/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3380 - mae: 0.4376\n",
      "Epoch 72/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2915 - mae: 0.4311\n",
      "Epoch 73/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2914 - mae: 0.4242\n",
      "Epoch 74/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2914 - mae: 0.4274\n",
      "Epoch 75/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3122 - mae: 0.4335\n",
      "Epoch 76/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2992 - mae: 0.4308\n",
      "Epoch 77/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2768 - mae: 0.4109\n",
      "Epoch 78/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2710 - mae: 0.4005\n",
      "Epoch 79/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2655 - mae: 0.3968\n",
      "Epoch 80/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2922 - mae: 0.4157\n",
      "Epoch 81/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2413 - mae: 0.3856\n",
      "Epoch 82/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2534 - mae: 0.3930\n",
      "Epoch 83/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2600 - mae: 0.3917\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2439 - mae: 0.3858\n",
      "Epoch 85/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2401 - mae: 0.3859\n",
      "Epoch 86/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2250 - mae: 0.3727\n",
      "Epoch 87/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2389 - mae: 0.3764\n",
      "Epoch 88/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2441 - mae: 0.3884\n",
      "Epoch 89/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2425 - mae: 0.3899\n",
      "Epoch 90/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2208 - mae: 0.3715\n",
      "Epoch 91/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2259 - mae: 0.3688\n",
      "Epoch 92/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2228 - mae: 0.3705\n",
      "Epoch 93/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.1846 - mae: 0.3368\n",
      "Epoch 94/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.1933 - mae: 0.3419\n",
      "Epoch 95/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.1967 - mae: 0.3490\n",
      "Epoch 96/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2032 - mae: 0.3500\n",
      "Epoch 97/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2116 - mae: 0.3542\n",
      "Epoch 98/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2018 - mae: 0.3523\n",
      "Epoch 99/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.1877 - mae: 0.3393\n",
      "Epoch 100/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.1866 - mae: 0.3383\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "for i in range(14):\n",
    "    true.append(i*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50208515] 0.5\n",
      "[0.9712072] 1.0\n",
      "[1.6022184] 1.5\n",
      "[2.0196908] 2.0\n",
      "[2.5250034] 2.5\n",
      "[3.0473042] 3.0\n",
      "[3.4569535] 3.5\n",
      "[4.150567] 4.0\n",
      "[4.4099627] 4.5\n",
      "[5.3311033] 5.0\n",
      "[4.8106184] 5.5\n",
      "[4.9897227] 6.0\n",
      "mae 0.21162564555803934\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "mae = 0\n",
    "for item in answer_2:\n",
    "    print(item,y_test[index])\n",
    "    mae += abs(item[0]-y_test[index])\n",
    "    index+=1\n",
    "print(\"mae\",mae/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1265852] 0.5\n",
      "[1.4937192] 1.0\n",
      "[1.9012432] 1.5\n",
      "[2.0438838] 2.0\n",
      "[2.1394658] 2.5\n",
      "[2.7669752] 3.0\n",
      "[2.9989803] 3.5\n",
      "[3.1679642] 4.0\n",
      "[2.9684603] 4.5\n",
      "[4.2142797] 5.0\n",
      "[4.619818] 5.5\n",
      "[4.844134] 6.0\n",
      "mae 0.6537794967492422\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "mae = 0\n",
    "for item in answer:\n",
    "    print(item,y_test[index])\n",
    "    mae += abs(item[0]-y_test[index])\n",
    "    index+=1\n",
    "print(\"mae\",mae/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(true,true,c='red')\n",
    "plt.scatter(answer,y_test,c='green')\n",
    "plt.scatter(answer_2,y_test,c='blue')\n",
    "plt.ylabel(\"True value\") \n",
    "plt.xlabel('Predicted value') \n",
    "plt.savefig('TL.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
