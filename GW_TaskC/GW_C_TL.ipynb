{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If using GPU.\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['reduced_data', 'waveforms', 'yeofrho']>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read database.\n",
    "f = h5py.File('GWdatabase.h5','r')   \n",
    "f.keys()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list that contains all the failure cases.\n",
    "fail_num = []\n",
    "index = 0\n",
    "for item in f['reduced_data']['tbounce(s)']:\n",
    "    if(item == -1):\n",
    "        fail_num.append(index)\n",
    "    index += 1\n",
    "fail_case = []\n",
    "for index in fail_num:\n",
    "    fail_case.append([f['reduced_data']['A(km)'][index],f['reduced_data']['omega_0(rad|s)'][index],f['reduced_data']['EOS'][index]])\n",
    "fail_list= []\n",
    "for item in fail_case:\n",
    "    tmp = str(item[2]).split(\"b'\")[1].split(\"'\")[0]\n",
    "    tmp = \"A\" + str(int(item[0])) + \"w\" + str(item[1]) + \"0_\" + tmp\n",
    "    fail_list.append(tmp)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose which label we want to predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the label of w.\n",
    "labels = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        labels.append(float(item.split('_')[0].split('w')[1]))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image data.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "data = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "        image = Image.open(title).convert('L')\n",
    "        data.append(np.array(image))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f28b2e860d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 256x256 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the data.\n",
    "plt.figure(figsize=(4, 4), dpi=64)\n",
    "plt.imshow(data[5], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the data type to numpy array\n",
    "data = np.array(data)\n",
    "X_train = data\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "#from keras.utils import np_utilsy\n",
    "from keras import backend as K\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1764, 256, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer the data shape for model training\n",
    "X_train = X_train.reshape(X_train.shape[0], 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using one hot to encode the label.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = Sequential()\n",
    "model_encoder.add(Conv2D(64, (5, 5), input_shape=(256, 256, 1), padding=\"same\", activation='relu'))\n",
    "model_encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_encoder.add(Conv2D(128, (5, 5), padding=\"same\", activation='relu'))\n",
    "model_encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_encoder.add(Conv2D(256, (5, 5), padding=\"same\", activation='relu'))\n",
    "model_encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_encoder.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model_encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_encoder.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model_encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_encoder.add(Dropout(0.5))\n",
    "model_encoder.add(Flatten())\n",
    "model_decoder = Sequential()\n",
    "model_decoder.add(Dense(1024, activation='relu'))\n",
    "model_decoder.add(Dense(512, activation='relu'))\n",
    "model_decoder.add(Dense(128, activation='relu'))\n",
    "model_decoder.add(Dense(32, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(model_encoder)\n",
    "model_1.add(model_decoder)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "441/441 [==============================] - 17s 33ms/step - loss: 4.4818 - acc: 0.0443\n",
      "Epoch 2/40\n",
      "441/441 [==============================] - 15s 33ms/step - loss: 3.4164 - acc: 0.0375 0s - loss: 3.4172\n",
      "Epoch 3/40\n",
      "441/441 [==============================] - 15s 33ms/step - loss: 3.3478 - acc: 0.0585\n",
      "Epoch 4/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 3.2226 - acc: 0.0900\n",
      "Epoch 5/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 2.9095 - acc: 0.1412\n",
      "Epoch 6/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 2.5819 - acc: 0.1561\n",
      "Epoch 7/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 2.3369 - acc: 0.2247\n",
      "Epoch 8/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 2.1911 - acc: 0.2380\n",
      "Epoch 9/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 2.0552 - acc: 0.2639\n",
      "Epoch 10/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.9221 - acc: 0.2915 0s - loss: 1.9231\n",
      "Epoch 11/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.8035 - acc: 0.3327 1s - loss\n",
      "Epoch 12/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.7392 - acc: 0.3421 0s - loss: 1.7394 - acc: 0.34\n",
      "Epoch 13/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.6487 - acc: 0.3742\n",
      "Epoch 14/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.6031 - acc: 0.3905\n",
      "Epoch 15/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.4266 - acc: 0.4511\n",
      "Epoch 16/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.4296 - acc: 0.4310 4s - loss\n",
      "Epoch 17/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.3740 - acc: 0.4463 1s -\n",
      "Epoch 18/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.3299 - acc: 0.4681\n",
      "Epoch 19/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.2451 - acc: 0.5170\n",
      "Epoch 20/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.1882 - acc: 0.5252 0s - loss: 1.1882 - acc: 0.52\n",
      "Epoch 21/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.0989 - acc: 0.5391\n",
      "Epoch 22/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 1.0416 - acc: 0.5709\n",
      "Epoch 23/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.9862 - acc: 0.6076 0s - loss: 0.9854 -\n",
      "Epoch 24/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.9409 - acc: 0.6200\n",
      "Epoch 25/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.9340 - acc: 0.6234\n",
      "Epoch 26/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.8719 - acc: 0.6600\n",
      "Epoch 27/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.8058 - acc: 0.6746\n",
      "Epoch 28/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.7526 - acc: 0.7015\n",
      "Epoch 29/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.7233 - acc: 0.7231\n",
      "Epoch 30/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.7070 - acc: 0.7068\n",
      "Epoch 31/40\n",
      "441/441 [==============================] - 15s 34ms/step - loss: 0.6343 - acc: 0.7784\n",
      "Epoch 32/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.6138 - acc: 0.7535\n",
      "Epoch 33/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.5993 - acc: 0.7767\n",
      "Epoch 34/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.5534 - acc: 0.8004\n",
      "Epoch 35/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.5289 - acc: 0.7877\n",
      "Epoch 36/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.4927 - acc: 0.8108\n",
      "Epoch 37/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.4739 - acc: 0.8209\n",
      "Epoch 38/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.4346 - acc: 0.8391\n",
      "Epoch 39/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.4049 - acc: 0.8512\n",
      "Epoch 40/40\n",
      "441/441 [==============================] - 15s 35ms/step - loss: 0.4166 - acc: 0.8314\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(x=X_train, y=y_train, epochs=40, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the GPU is out of memory while testing, we may need to save the trained model, restart, then load the model. \n",
    "model_encoder.save('TL_encoder_omega.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_encoder = keras.models.load_model('TL_encoder_omega.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFER LEARNING\n",
    "a = []\n",
    "f = h5py.File('20210705.h5','r')   \n",
    "index = 0\n",
    "for item in f:\n",
    "    check = np.array(f[item])\n",
    "    if(check.size > 0):\n",
    "        if(float(item.split('w')[1]) < 6.1):\n",
    "            if(item.split('w')[0] != 'A467'):\n",
    "                a.append(index)\n",
    "            index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFER LEARNING\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "X_train = []\n",
    "X_test = []\n",
    "for i in range(60): \n",
    "    if(i in a):\n",
    "        title = 'test_new/'+ str(i) + '.jpeg'\n",
    "        image = Image.open(title).convert('L')\n",
    "        X_train.append(np.array(image))\n",
    "    else:\n",
    "        title = 'test_new/'+ str(i) + '.jpeg'\n",
    "        image = Image.open(title).convert('L')\n",
    "        X_test.append(np.array(image))\n",
    "y_train = []\n",
    "y_test = []\n",
    "f = h5py.File('20210705.h5','r')   \n",
    "index = 0\n",
    "for item in f:\n",
    "    check = np.array(f[item])\n",
    "    if(check.size > 0):\n",
    "        if(float(item.split('w')[1]) < 6.1):\n",
    "            if(index in a):\n",
    "                y_train.append(float(item.split('w')[1]))\n",
    "            else:\n",
    "                y_test.append(float(item.split('w')[1]))\n",
    "            index += 1\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 256, 256, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_decoder2 = Sequential()\n",
    "model_decoder2.add(Dense(1024, activation='relu'))\n",
    "model_decoder2.add(Dense(512, activation='relu'))\n",
    "model_decoder2.add(Dense(128, activation='relu'))\n",
    "model_decoder2.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder.trainable = True\n",
    "model_2 = Sequential()\n",
    "model_2.add(model_encoder)\n",
    "model_2.add(model_decoder2)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.000003)\n",
    "model_2.compile(loss='mse', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 39ms/step - loss: 0.1720 - mae: 0.3238 - val_loss: 0.2231 - val_mae: 0.3682\n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=100, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_2 = model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on Richar's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('GWdatabase.h5','r')  \n",
    "#get the label of w.\n",
    "labels = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        labels.append(float(item.split('_')[0].split('w')[1]))\n",
    "    index += 1\n",
    "#read image data.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "data = []\n",
    "index = 0\n",
    "for item in f['waveforms']:\n",
    "    if(item not in fail_list):\n",
    "        title = 'Final_tbounce/'+ str(index) + '.jpeg'\n",
    "        image = Image.open(title).convert('L')\n",
    "        data.append(np.array(image))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the data type to numpy array\n",
    "data = np.array(data)\n",
    "X_train = data\n",
    "y_train = labels\n",
    "y_train = np.array(y_train)\n",
    "#transfer the data shape for model training\n",
    "X_train = X_train.reshape(X_train.shape[0], 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(256, 256, 1), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.000003)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "111/111 [==============================] - 8s 54ms/step - loss: 34.0673 - mae: 4.6114\n",
      "Epoch 2/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 20.9456 - mae: 3.6823\n",
      "Epoch 3/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 18.4016 - mae: 3.4382\n",
      "Epoch 4/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 14.9659 - mae: 3.1015\n",
      "Epoch 5/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 13.1375 - mae: 2.9350\n",
      "Epoch 6/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 11.9523 - mae: 2.7886\n",
      "Epoch 7/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 10.1003 - mae: 2.5248\n",
      "Epoch 8/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 7.1320 - mae: 2.0578\n",
      "Epoch 9/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 5.4531 - mae: 1.7894\n",
      "Epoch 10/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 4.3124 - mae: 1.5801\n",
      "Epoch 11/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 3.6123 - mae: 1.4827\n",
      "Epoch 12/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 3.3627 - mae: 1.4117\n",
      "Epoch 13/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 2.7380 - mae: 1.2893\n",
      "Epoch 14/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 2.6372 - mae: 1.2505\n",
      "Epoch 15/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 2.3533 - mae: 1.2047\n",
      "Epoch 16/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 2.0615 - mae: 1.1251\n",
      "Epoch 17/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.9210 - mae: 1.0854\n",
      "Epoch 18/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.8973 - mae: 1.0993\n",
      "Epoch 19/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.6912 - mae: 1.0279\n",
      "Epoch 20/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.5522 - mae: 0.9696\n",
      "Epoch 21/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.4100 - mae: 0.9274\n",
      "Epoch 22/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.2998 - mae: 0.8939\n",
      "Epoch 23/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.3887 - mae: 0.9225\n",
      "Epoch 24/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 1.2644 - mae: 0.8704\n",
      "Epoch 25/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 1.0898 - mae: 0.8212\n",
      "Epoch 26/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 1.1161 - mae: 0.8160\n",
      "Epoch 27/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 1.0290 - mae: 0.8031\n",
      "Epoch 28/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 1.0593 - mae: 0.8210\n",
      "Epoch 29/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.9195 - mae: 0.7585\n",
      "Epoch 30/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 1.0105 - mae: 0.7973\n",
      "Epoch 31/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.8969 - mae: 0.7601\n",
      "Epoch 32/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.9319 - mae: 0.7625\n",
      "Epoch 33/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.8384 - mae: 0.7241\n",
      "Epoch 34/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.8165 - mae: 0.7116\n",
      "Epoch 35/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.8176 - mae: 0.7162\n",
      "Epoch 36/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.8070 - mae: 0.6988\n",
      "Epoch 37/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.7411 - mae: 0.6897\n",
      "Epoch 38/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.7103 - mae: 0.6663\n",
      "Epoch 39/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6908 - mae: 0.6414\n",
      "Epoch 40/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5981 - mae: 0.6128\n",
      "Epoch 41/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6725 - mae: 0.6462\n",
      "Epoch 42/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6217 - mae: 0.6071\n",
      "Epoch 43/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6774 - mae: 0.6581\n",
      "Epoch 44/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6387 - mae: 0.6170\n",
      "Epoch 45/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5716 - mae: 0.5904\n",
      "Epoch 46/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.6058 - mae: 0.6040\n",
      "Epoch 47/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5757 - mae: 0.5903\n",
      "Epoch 48/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5248 - mae: 0.5703\n",
      "Epoch 49/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.4899 - mae: 0.5473\n",
      "Epoch 50/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5065 - mae: 0.5650\n",
      "Epoch 51/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.5031 - mae: 0.5587\n",
      "Epoch 52/100\n",
      "111/111 [==============================] - 6s 56ms/step - loss: 0.4728 - mae: 0.5471\n",
      "Epoch 53/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4780 - mae: 0.5415\n",
      "Epoch 54/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4471 - mae: 0.5251\n",
      "Epoch 55/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4533 - mae: 0.5395\n",
      "Epoch 56/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4493 - mae: 0.5268\n",
      "Epoch 57/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4291 - mae: 0.5101\n",
      "Epoch 58/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4283 - mae: 0.5078\n",
      "Epoch 59/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4423 - mae: 0.5150\n",
      "Epoch 60/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4286 - mae: 0.5084\n",
      "Epoch 61/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.4098 - mae: 0.4967\n",
      "Epoch 62/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3796 - mae: 0.4744\n",
      "Epoch 63/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3616 - mae: 0.4740\n",
      "Epoch 64/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3476 - mae: 0.4652\n",
      "Epoch 65/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3740 - mae: 0.4820\n",
      "Epoch 66/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3364 - mae: 0.4578\n",
      "Epoch 67/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3492 - mae: 0.4679\n",
      "Epoch 68/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3420 - mae: 0.4541\n",
      "Epoch 69/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3699 - mae: 0.4794\n",
      "Epoch 70/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3183 - mae: 0.4390\n",
      "Epoch 71/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3380 - mae: 0.4376\n",
      "Epoch 72/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2915 - mae: 0.4311\n",
      "Epoch 73/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2914 - mae: 0.4242\n",
      "Epoch 74/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2914 - mae: 0.4274\n",
      "Epoch 75/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.3122 - mae: 0.4335\n",
      "Epoch 76/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2992 - mae: 0.4308\n",
      "Epoch 77/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2768 - mae: 0.4109\n",
      "Epoch 78/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2710 - mae: 0.4005\n",
      "Epoch 79/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2655 - mae: 0.3968\n",
      "Epoch 80/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2922 - mae: 0.4157\n",
      "Epoch 81/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2413 - mae: 0.3856\n",
      "Epoch 82/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2534 - mae: 0.3930\n",
      "Epoch 83/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2600 - mae: 0.3917\n",
      "Epoch 84/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2439 - mae: 0.3858\n",
      "Epoch 85/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2401 - mae: 0.3859\n",
      "Epoch 86/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2250 - mae: 0.3727\n",
      "Epoch 87/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2389 - mae: 0.3764\n",
      "Epoch 88/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2441 - mae: 0.3884\n",
      "Epoch 89/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2425 - mae: 0.3899\n",
      "Epoch 90/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2208 - mae: 0.3715\n",
      "Epoch 91/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2259 - mae: 0.3688\n",
      "Epoch 92/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2228 - mae: 0.3705\n",
      "Epoch 93/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.1846 - mae: 0.3368\n",
      "Epoch 94/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.1933 - mae: 0.3419\n",
      "Epoch 95/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.1967 - mae: 0.3490\n",
      "Epoch 96/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2032 - mae: 0.3500\n",
      "Epoch 97/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2116 - mae: 0.3542\n",
      "Epoch 98/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.2018 - mae: 0.3523\n",
      "Epoch 99/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.1877 - mae: 0.3393\n",
      "Epoch 100/100\n",
      "111/111 [==============================] - 6s 55ms/step - loss: 0.1866 - mae: 0.3383\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the GPU is out of memory while testing, we may need to save the trained model, restart, then load the model. \n",
    "model.save('Omega_Cont.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('Omega_Cont.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "for i in range(14):\n",
    "    true.append(i*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3576311] 0.5\n",
      "[0.7322973] 1.0\n",
      "[1.1034969] 1.5\n",
      "[1.9853213] 2.0\n",
      "[2.4198437] 2.5\n",
      "[3.3171659] 3.0\n",
      "[3.6547902] 3.5\n",
      "[4.4458766] 4.0\n",
      "[4.5992327] 4.5\n",
      "[4.215664] 5.0\n",
      "[4.6599793] 5.5\n",
      "[5.1242785] 6.0\n",
      "mae 0.368212769428889\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "mae = 0\n",
    "for item in answer_2:\n",
    "    print(item,y_test[index])\n",
    "    mae += abs(item[0]-y_test[index])\n",
    "    index+=1\n",
    "print(\"mae\",mae/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2646691] 0.5\n",
      "[1.1255358] 1.0\n",
      "[1.5898265] 1.5\n",
      "[1.8182561] 2.0\n",
      "[2.2171807] 2.5\n",
      "[2.5154135] 3.0\n",
      "[2.7071548] 3.5\n",
      "[3.4759088] 4.0\n",
      "[3.545564] 4.5\n",
      "[3.197634] 5.0\n",
      "[3.365396] 5.5\n",
      "[5.245442] 6.0\n",
      "mae 0.7410068015257517\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "mae = 0\n",
    "for item in answer:\n",
    "    print(item,y_test[index])\n",
    "    mae += abs(item[0]-y_test[index])\n",
    "    index+=1\n",
    "print(\"mae\",mae/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(true,true,c='red')\n",
    "plt.scatter(answer,y_test,c='green')\n",
    "plt.scatter(answer_2,y_test,c='blue',marker=\"^\")\n",
    "plt.ylabel(\"True value\") \n",
    "plt.xlabel('Predicted value') \n",
    "plt.savefig('TL.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
